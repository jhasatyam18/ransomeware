{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Datamotive Workload Mobility product suite delivers a disaster recovery and workload migration service and offers cloud economics to help keep your disaster recovery and migration costs under control. Datamotive Workload Mobility can be used to protect your vSphere virtual machines by replicating them periodically to the cloud and recovering them as needed to a target public cloud platform as a native cloud instance (E.g., protected virtual machine is recovered as a native AWS EC2 instance or a GCP Compute instance). The Datamotive Replication Engine replicates the entire protected VM over to the target platform. This includes the OS, the OS configuration, the registry entries, application and application data, everything inside the VM is replicated. The first replication iteration is a full copy of the VM from the source environment to the target cloud platform. Following iterations, only replicate the changed data from the previously successfully completed replication iterations. Datamotive does not require or need any agents to be deployed or installed on the protected VMs. Each VM is completely treated as a black box by Datamotive. As a result, the enterprises workloads (VMs) require no operational management, nor require any special security configurations. There is also minimal performance impact on the business applications. The Datamotive Replication Engine also enables near instantaneous recovery of the workloads in the target cloud platforms. When the workloads are recovered or migrated in the cloud, they are already in the native cloud platform (AWS EC2 instance or GCP Compute instance formats). No additional conversion or rehydration or seeding is required. Datamotive provides an unprecedented Recovery Time Objective (RTO) of 10 minutes per protected virtual machine. Similarly provided, in the case of Migration, is a Cutover Time Objective (CTO) of 10 minutes per VM with zero data loss. The Datamotive platform currently provides and supports Disaster Recovery and Migration use-cases. Very soon, Datamotive will also be providing and supporting Ransomware Recovery and Rapid Dev/Test Deployments (Cloud Cloning) use-cases. a Datamotive Component Architecture Datamotive Replication Service \u2013 a virtual appliance installed in the VMware vSphere environment where the virtual machines to be protected are running under normal circumstances. This appliance also presents a user interface (UI), a CLI and REST APIs for the IT administrators to use under normal circumstances. Datamotive Cloud Service \u2013 a virtual appliance deployed in the public cloud environment (AWS or GCP) where the protected virtual machines will be recovered in the event of a disaster or when VMs are migrated to the target public cloud. This appliance also presents a user interface (UI), a CLI and REST APIs for the IT administrators to use in the event of a disaster and the on-premises Datamotive Replication Service is un-available. Migration and Recovery jobs can be triggered using this interface. Datamotive Prep Appliance \u2013 a Windows virtual appliance deployed in the public cloud environment (AWS or GCP). This appliance is only powered-on and used when recovering or migrating Windows VMs. Capabilities and Benefits Datamotive Workload Mobility provides the following key capabilities: Hybrid, Multi Cloud Simplicity \u2013 Provides comprehensive SaaS simplicity across on-demand Disaster Recovery, Migration and Ransomware Recovery Agentless Model \u2013 Datamotive requires no agents on the protected VMs, leading to significantly simpler management of VMs under normal circumstances. Minimal performance impact on the protected VMs as compared to agent-based solutions and most importantly, no need to open additional (or per protected VM) ports in your firewall. Follow your Zero Trust Security policies completely. Industry Best SLAs \u2013 Datamotive provides 10 minutes or less RTO or CTO regardless of the size of the workload. If your VMs/workloads are 100 GB or 2 TB, Datamotive will always take 10 minutes or less to completely recover them in the cloud. Cost Optimized \u2013 Reduce your capex and opex significantly by leveraging the economics and pay-per-use model of public clouds. Only pay for cloud storage costs. Pay for compute and network only when a disaster strikes, and your workloads are recovered in the cloud. Unlimited Test Recovery \u2013 Execute Test Recovery workflows in a network fenced environment to test your replication consistency safely and securely. Ransomware Recovery \u2013 Protect your workloads from cybercrime attacks by keeping point-in-time copies in air-gapped, low-cost public cloud storage. In the event of an attack, choose the latest copy and recover your workloads in the cloud in minutes. Support Matrix VMware vCenter Server 5.5 vCenter Server 6.0 vCenter Server 6.5 (U1, U2) vCenter Server 6.5 (U3) vCenter Server 6.7 vCenter Server 6.7 (U1, U2, U3) vCenter Server 7.0 ESXi 5.5 ESXi 6.0 ESXi 6.5 (GA, U1, U2) ESXi 6.5 (U3) ESXi 6.7 (GA, U1, U2) ESXi 7.0 (GA) Cloud Providers Following are the supported public cloud providers. AWS (Amazon Web Services) Google Cloud Guest OS OS Kernel Version Support CentOS 6 - CentOS 7.9 3.10.0-1160.el7.x86_64 CentOS 8 - Red Hat Enterprise Linux 6 - Red Hat Enterprise Linux 7.9 3.10.0-1160.el7.x86_64 Red Hat Enterprise Linux 8 - Ubuntu 14 4.4.0-148-generic Ubuntu 16 4.15.0-45-generic 4.15.0-142-generic 4.10.0-28-generic Ubuntu 18 5.4.0-42-generic, 5.4.0-72-generic 5.4.0-91-generic Ubuntu 20 5.11.0-27-generic Oracle Linux 6 - Oracle Linux 7 - Oracle Linux 8 - Debian 9 - Debian 10 - Suse Linux 12 - Suse Linux 15 - Microsoft Windows 10 Professional MS Windows Server 2012 (Standard, Datacenter) Reverse recovery for Win2k12 is currently not supported to VMWare (specifically for VMWare to AWS) MS Windows Server 2012-R2 (Standard, Datacenter) Reverse recovery for Win2k12-R2 is currently not supported to VMWare (specifically for VMWare to AWS) MS Windows Server 2016 (Standard, Datacenter) MS Windows Server 2019 (Standard, Datacenter) Supported Browser Versions Browser Names Versions Mozilla Firefox 98.0.2 (64-bit) Google Chrome Version 99.0.4844.82 (Official Build) (64-bit) Authentication Open the Datamotive UI through URL: \\< Datamotive_Service_IP >:5000 Provide the username and password and press Login On successful login, User will see the Datamotive Dashboard. By default Datamotive will create following three users Administrator DRadmin Guest Default password for all the users is \u2018admin\u2019 Note: If you are login first time then for security reasons password change is must. Provide the current password and new password. Click on change password button to set new password for the system. Dashboard The Dashboard provides you with an at-a-glance overview of the data protection status of your environment. The Dashboard contains the following features. Title Windows Title windows will give overall status on your configured and protected environment. Title Description Sites Sites configured on the node. Protection Plans Protection plans configured. Protected Machines Total number of protected virtual machines Storage Overall protected storage size. Alert Statistics Active alter which needs a user action acknowledgement or action on it. RPO and RTO Statistics Current recovery time objective and recovery point objective. Title Description RPO Average recovery point objective value RTO Average of recovery time object value Test Executions Test executions completed successfully. Full Recovery Virtual machines recovered successfully. Migrations Virtual machines migrated successfully. Replication Statistics Replication statistics provides a central snapshot overview of your protected environment replication jobs. Label Description Completed Successfully completed replication iterations. Running Replication iterations are in-progress. Failed Failed replication iterations. Change Rate Average data change rate for all protected virtual machines Data Reduction Average percentage of data reduction for all the completed replications. Jobs Jobs shows the recently started or completed task in the system. Virtual Machine Protection Analysis Virtual machine protection analysis shows the overall status of recovery site environment in terms of total discovered virtual machines with percentage of protected and unprotected virtual machines. In addition to protection analysis, this wizard also provides the details for replication statistics of virtual machines which are in-sync and not in-sync. Bandwidth Usage Bandwidth usage provide the details network usage of the system for last 12 hours. The bandwidth usage chart shows data downloaded and uploaded for last 12 hours. Site Connections Provides connection details of configured sites in terms of data flow i.e., from which source site data replication is configured for target site. Events Events are records of user actions or system actions that occurred in the Datamotive system. The Events widget provides most recent 5 events generated in the system. Nodes Configuration Nodes are entities where the Datamotive server is installed (Ex. AWS, GCP, VMWare, etc.). Datamotive Nodes are of different types wiz Management, Replication, Dedup & Win Prep. Each node has specific functionality. Management: Node for performing Datamotive management operations. There must be one and only Management node for each site. Replication: Nodes responsible for performing replication activities. These can be added based on number of Virtual Machine disks to be replicated in parallel. Any number of nodes can be added to meet the requirement. Dedup: This is a special type of node required to support deduplication. This node is required only on the Recovery site. Win Prep: This is also a special type of node required only on Recovery site to perform Windows workloads recovery. For all the nodes, Datamotive provides separate OVAs & cloud specific machine images. Once Node of given type is deployed in the infrastructure, it needs to be added in the Datamotive Management server. Nodes must be deployed and configured in following manner. Management Node: Deploy 1 management node per protected site. Local node representing the management node automatically gets registered. Remote Management Node: Deploy 1 management node per recovery site. Register the management nodes from Recovery Sites in Management Node of Protected Site. Replication Nodes: Deploy replication node based on load. Once deployed register replication node in the local management server. Replication nodes are always added to local management node only. Dedup Node: Deploy the Dedup node on Recovery Site. Once deployed, register the Dedup node with Management Node on the Recovery Site. Win Prep Node: Deploy the Win Prep node on Recovery Site. Once deployed, register the Win Prep node with Management Node on the Recovery Site. To Access Node option, Go to Configure -> Nodes (Note- By default the Local node will be configured.) To add new node - Click On \u201c+ New \u201d option as shown below - It consists of the below options- Name The desired name to identification Hostname This is FQDN or IP address of the server Username This is the username of the Datamotive Engine Password This is the password of the Datamotive Engine Type The type of Datamotive server which is being added. Type consists of 4 options - Management, Replication, Prep Node and Dedupe Server In Type select the appropriate option from the drop down - Type Description Management Used when you would want to manage the servers (Edit, remove, and modify, etc) Replication Used when you would want to replicate the servers to the target site Prep Node Prep Node is used when you would want to recover the Windows server Dedupe Server Used for de-duplication of data (Note \u2013 Based on the selection of Type, further details need to be entered). Ex. In option, the management type is selected. It consists of the below options - Platform Type Platform where the node is deployed Management port Port on which the management service runs (By default, it 5000) Replication Data Port Port on which the replication data service runs (By default, it 5001) Replication Controller Port Port on which the replication controller service runs (By default, it 5003) Encryption Key Data will be encrypted using this key while transferring from one node to another node. The key for the node can be accessed in the remote management node, under the node configuration section. Once the details are entered click on Configure option. Sites configuration Sites are environment setup for Protection plan to configure. Site consists of platform type and platform details. In the Datamotive UI, go to Configure tab on the left-hand side panel and select Sites. To do Site can be of following types: Protection - A protection site is the source of the protection plan workload replication. Recover - A Recover site is the destination for the protection plan workload replication. Create Site To create site, click the \u201c+ New\u201d button and Create site windows will pop-up. The common inputs are- Name : Enter a desired name to identify the site Description : Short information about the site Site Type : (Protect/Recover) - Select the site type based on source or destination. Platform Type : Select the Platform type - VMware/AWS/GCP. Node : Select the node based on the Platform type where the workloads are hosted (Note: Based on the platform type and node the options change) Platform Type: VMWare: - vCenter Server IP: Enter the vCenter Server IP address where the workloads are hosted Port : By default, 443 Username : Enter the vCenter Server username Password : Enter the password for vCenter user AWS: - Region : Select the desired region where the workloads will be replicated/recovered Zone : Select the desired zone in the region where the workloads will be replicated/recovered Access Key : AWS User Access Key Secret Key : AWS User Secret Key GCP: - Region : Select the desired region where the workloads will be replicated/recovered Zone : Select the desired zone in the region where the workloads will be replicated/recovered Project ID : Enter the project id from the GCP console Click on configure to create the site and on successful creation, site will be listed in the list view. V Center Server IP Edit Site To Edit a site, click on Edit button and then Edit windows will pop-up. Edit the input which need to be changed and click on configure to save the configuration. Remove Site Click on Remove button to delete one or more sites. On click of confirm, the sites will be deleted. Protection plan Navigation: Home \u2014> Configuration \u2014> Protection Pl Protection plan consists of a group of workloads which will be replicated from source to destination sites Create Protection Plan Prerequisite VMware platform : VMware tools must be installed in all the Virtual Machines which needs to be protected. CBT (Change block tracking) must be enabled for all the Virtual Machines and their disks. To create a new protection plan, click on + New button in protection plan list, create protection plan wizard is shown. Follow the guided steps to configure protection plan. General Name : Desired name of the protection plan. Protect Site : Source protection site. Recovery Site : Destination recovery site. Virtual Machines Select the virtual machines to be protected and click next. Use search & pagination to find virtual machines. Recovery Configuration Provide the virtual machine specific recover configuration which will be used for creation of instance on recovery site. General Instance Type : Instance type on cloud site - Example t2.micro on AWS or n1-standard-1 on GCP. Volume Type : Instance volume type on cloud site - Example GP-2 on AWS or standard on GCP. Volume IOPS : IOPs value for supported Volume Types. Please note that the IOPs values are submitted for volume creation without validations. Make sure that all the rules specific to selected volume type are followed while specifying the IOPs value Tags : Instance tags. Example \u2013 Tag Key \u2013 Name Tag value \u2013 dm-repl-node Network : For instance, network configuration click on config button, will open a network configuration popup window. For AWS platform as recovery site, the following configuration options are provided- VPC : Virtual Private Cloud (Amazon VPC) enables you to launch AWS resources into a virtual network that you've defined. Create from Source: This option is used when you need to copy the network configuration from the source instance. All the options like subnets, IP address and security groups get auto-filled as the source instance Subnet : subnet ID which will assigned to the instances in this protection plan. Auto Public IP : Click on the checkbox if you want to auto assign a public Ip to instance. Note - only one network card can be configured if public Ip is enabled. Elastic IP for instance : Select from allocated elastic IP address pool if any. Private IP : Provide the internal IP address for the instance or leave blank for auto assignment. (Please ensure to specify Private IP in the same range as that of given Subnet and is unique too) Security Groups : Select the security groups all configure inbound and outbound traffic for the instance. For GCP platform provided the following details Network : Network which will be assigned to the instances in the Protection Plan Subnet : subnet ID which will assigned to the instances in this protection plan. Private IP : Provide the internal IP address for the instance or leave blank for auto assignment. External IP : Select one of the following options if external Ip address is required for the selected network card else select none. 1. Auto: gcp will assign a Ip address from its public Ip pool. 2. None: select if external not required. 3. Reserved IP address, GCP project reserved Ip address, will be listed along with above two options. You can select any reserved Ip address from the list. Network Tier : Network Service Tiers lets you optimize connectivity between systems on the internet and your Google Cloud instances. Premium Tier delivers traffic on Google's premium backbone, while Standard Tier uses regular ISP networks Firewall Tags: The target tag defines the Google Cloud VMs to which the rule applies. Replication Scripts : Datamotive supports executing custom scripts for individual VM and complete protection plan as well.IT supports both, pre and post scripts. To use pre or post scripts, first upload the pre & post scripts to Datamotive management node on recovery and protection site using scripts section in settings. Once the scripts are uploaded, they will be visible in the pre and post replication scripts option - Pre \u2013 The pre script will be executed before every iteration when the replication starts. For example, you need to stop the service of a particular server before the replication starts Post - The post script will be executed after every iteration when the replication is completed. For example, you need to export the replicated data size to a particular file. Recovery Scripts : Datamotive supports executing custom scripts on recovery of individual virtual machine and complete protection plan as well. Datamotive supports both, Pre & Post scripts. The scripts are executed on the Datamotive management node. To use pre or post scripts, first upload the pre & post scripts to Datamotive management node on recovery and protection site using scripts section in settings. Once these scripts are uploaded, they will start showing up in drop down menu of scripts in create & update protection plan wizard. Once configured, the scripts will get invoked as below. Pre: Script will run before Datamotive executes recovery workflow for a VM when configured as a VM pre-script and before recovery of protection plan when configured as Protection Plan pre-script. Typically, this script should take care of infrastructure configurations required for the virtual machine to come up. For example, configuring firewall rules for this VM, creating domains for authentication etc. Post: Script will run after the entity is recovered when configured as VM post-script and after Protection Plan recovery when configured as Protection Plan post-script. Typically, this script should take care of recovered entity specific configurations. For example. Configuring application properties with new internal IPs etc. Scripts Input: Currently, Datamotive supports only shell scripts for execution. In future, binding for different languages will be provided. On invocation the script is provided with following parameters in the order. Pre-script: \\<None> Post-script: JSON string with following format { [ { \u201cName\u201d: \\<VM Name>, \u201cIP\u201d: \\<Newly assigned IP address of recovered VM>, \u201cUsername\u201d: \\<Login username of the recovered VM>, \u201cPassword\u201d: \\<Login password of the recovered VM> } ] } Scripts Output: The scripts are checked for it\u2019s completion and the process exit status is captured. If there are no errors in executing the script, Datamotive considers it to be successfully executed. If there are errors, the recovery is marked as Partially Completed. Boot Order Using boot order configuration defines the boot delay and virtual machine boot order. Boot Delay : Delay in seconds between virtual machines specified in the boot order Boot Order : Order in which virtual machines will get recovered or migrated. Replication Configuration Start Time : Time from when protection plan replication will start. Replication interval : Time interval in which the virtual machine\u2019s changed data will be replicated. Encryption On Wire : Data encryption while transferring from source to destination. Compression : Data compression while transferring from source to destination. Dedupe : Enables the data deduplication. Note: Deduplication node should be pre-configured on recovery site before using this feature. Differential Reverse Replication: Enable this feature if you want to allow recovered machines from the recovery site to replicate back to its original source site. Scripts Replication Scripts: These are scripts which would run before or after every replication iteration. Pre Script: The pre script will be executed before every iteration when the replication starts for this protection plan. Post Script- The post script will be executed after every iteration when the replication is completed for this protection plan. Recovery Scripts: This are scripts which would run before or after the recovery of the VM/instance Pre Script: Pre scripts which will run before recovery workflow for this protection plan. Post Script: Post scripts which will run after all the instances are recovered on recovery site. Summary Review the summary for the protection plan and click finish to configure the protection plan. On successful configuration, replication jobs will start for the virtual machines selected for this protection plan. Protection Plan Actions Action on protection plan is available through the protection plan list and through the protection plan details page. Action will get enable depending upon the context and state of the protection plan. Actions available through the protection plan data grid view. Actions available through the protection plan details Actions for source site Actions for recovery site New: Click to configure new protection plan. Edit: Select protection plan from the list and click edit. Edit protection plan wizard will get open. In edit protection following operations were allowed Add new virtual machine to plan. Remove protected virtual machine from the plan. This action gets completed on next successful iteration of the protection plan. The VM shows as \u201cRemoving\u201d till that time. Recovery configuration modification. Boot order configuration & modification. Replication configuration Scripts modification. Start : Start Replication for the selected protection plan. Stop: Stop the protection plan replication. Remove: To remove the protection plan, click on the Remove button and it will ask for the confirmation. On confirm, the protection plan will get deleted. Note protection plan should be in stopped state with no running jobs. Recovery To initiate recovery or migration go to Home \u2014> Configuration \u2014> Protection Plan -> Click on the protection plan on which recovery or migration operation need to perform. Click on the Actions button. All available operation will get listed. Test Recovery Prerequisite At least one replication job has been completed successfully for the virtual machine and the sync status for that job should be In-synch. Virtual Machines Select the virtual machines for the test recovery. Provide the credentials to execute the pre and post scripts. If there are no scripts for the virtual machine, then credentials are not mandatory. Credentials are not stored anywhere and only been used for the workflow. NOTE: For Windows recovery on AWS, Credentials are mandatory even if there are no scripts. Recovery Configuration Install System Agents: For AWS, install OS agents like EC2Launch and SSMAgents. For GCP, install google os-config and compute-engine agents. Install Cloud Packages : For AWS. install AWS Cloud SDK and for GCP, install GCP Cloud SDK. Summary Review the summary and click on finish to start the test recovery. This will start the test recovery jobs for the selected virtual machines and jobs can be monitored in the Home \u2014> Jobs \u2014> Recovery. Test Recovery validation Check the status of the virtual machine's recovery jobs in the Home \u2014> Jobs \u2014> Recovery. Check the Cloud Console (AWS and GCP) for the instances with the virtual machines name and their running status. AWS also has status checks. On successful completion of recovery jobs, IP Address can be found for the new running instances. For Windows machines, download the RDP file by click the download button right next to the IP address and check the windows machine through RDP. For Linux machines, copy the IP address and check the linux machine through ssh. Note: Once the validations are completed, Datamotive recommends to remove the Test Recovered instance. Full Recovery To perform full recovery after disaster in the source site, open Management Application on Recovery Site and go to Home \u2014> Configuration \u2014> Protection Plan \u2013> Click on the Protection plan. Click on Action button and select Recovery Prerequisite: At least one replication job has been completed successfully for the virtual machine and the sync status for that job should be init-success. Virtual Machines Select the virtual machines for the test recovery. Provide the credentials to execute the pre and postscripts. If there are no scripts for the virtual machine, then credentials are not mandatory. Credentials are not stored anywhere and only been used for the workflow. NOTE: For Windows recovery on AWS, Credentials are mandatory even if there are no scripts. Recovery Configuration Install System Agents: For AWS, install OS agents like EC2Launch and SSMAgents. For GCP, install google os-config and compute-engine agents. Install Cloud Packages : For AWS. install AWS Cloud SDK and for GCP, install GCP Cloud SDK. Recovery Summary Review the summary and click on finish to start the test recovery. This will start the test recovery jobs for the selected virtual machines and jobs can be monitored in the Home \u2014> Jobs \u2014> Recovery jobs. NOTE: If the replication job is on-going at the time of Full Recovery, then the instance will be recovered from the last known good state. Migration To migrate the workloads, go to Home \u2014> Configuration \u2014> Protection Plan \u00e0 Click on the protection on which migration need to perform, on the Recovery site. Click on actions buttons and select Migrate Prerequisite: In case of migration, to make sure there is no loss of data, the virtual machine(s) should be in power off state and the last replication jobs should be successfully completed with zero changed data. Virtual Machines Select the virtual machines and provide the credentials if there are pre- or post-configured for these virtual machines. Note: For Windows machine in AWS, credentials are mandatory. Recovery Configuration Install System Agents: For AWS, install OS agents like EC2Launch and SSMAgents. For GCP, install google os-config and compute-engine agents. Install Cloud Packages : For AWS. install AWS Cloud SDK and for GCP, install GCP Cloud SDK. Summary Review the summary and click on finish to start the Migration . This will start the test migration jobs for the selected virtual machines and jobs can be monitored in the Home \u2014> Jobs \u2014> Recovery jobs. Job's view after migration completed Jobs Navigation: Home --> Jobs You can use the Jobs page to monitor the overall status of replication and recovery jobs. Replication The Replication Jobs tab provides details about all the running, completed, and failed replication iterations. The Replication job section has the following sub-section to show replication jobs base on the grouping criteria. Protection Plan Navigation: Home --> Jobs --> Select Protection Plan. Protection plan replication details provide a list of protection plans. Each protection plan has its associated virtual machine replication information. click icon or title to view protection plan level details. Column Name Description Name Name of virtual machine associated with the protection plan. Iteration The total number of replication iterations completed. Total Changed Total data changed. Total Transferred Total data transferred to the replication server. Data Reduction (%) Overall data reduction. Job Status Status of latest replication iteration. Completed : Replication was completed successfully. Started : Replication is running. Partially Completed : Replication completed with errors. Failed : Replication failed. Sync Status Virtual machine sync status. Init-success : The first iteration completed successfully. Init-in-progress : The first iteration is running. Init-failed : The first iteration failed. In-sync : Iteration is completed within configured replication interval time. Exceeded interval : Iteration is completed but took more time than configured replication interval time. Sync-failed : Replication iteration failed. Virtual Machines Provides a list of replication details for each protected virtual machine. Note: For failed jobs, hover on the Sync Status column to get details of the status. Hover on the Replication Duration column to get Replication start & end time. Column Name Description Virtual Machine Name of the protected virtual machine. Iteration Total number of replication iterations completed. Changed Total changed data discovered. Transferred Total data transferred to the replication server. Replication Duration Time took to complete iteration. Job Status Status of replication iteration. Sync Status Virtual machine sync status. Disks Provide a list of replication details for each protected virtual machine disk/volume. Column Name Description Virtual Machine Name of the protected virtual machine. Disk Id Disk id of virtual machine. Data Changed Total changed data discovered for the disk. Data Transferred Total data transferred to the replication server. Replication Duration Time took to complete iteration. Job Status Status of replication iteration. Recovery Jobs The Recovery jobs tab provides details about all the running, completed and failed recovery operations. Protection Plan Protection plan recovery details provide a list of protection plans. Each protection plan has its associated recovered (Full / Test) or migrated virtual machine information. click icon or title to view protection plan level details. Column Name Description Name Name of virtual machine associated with the protection plan. Duration The time required to complete the recovery. Recovery Type Recovery Type (Full Recovery, Test Recovery or Migration) Status Recovery/Migration status. Virtual Machines Provides a list of recovered (Test/Full) or migrated virtual machines. Column Name Description Virtual Machine Name of virtual machine. Duration The time required to complete the recovery/migration. Recovery Type Recovery Type (Full Recovery, Test Recovery or Migration) Job Status Recovery job status. Completed : Recovery completed successfully. Started : Recovery job is running. Partially Completed : Recovery completed with errors. Failed : Recovery failed. IP Address Recovered virtual machine IP address. Monitor Monitor Option is used to see the events, alerts and customized reports as they are generated. In Monitor, there are 3 options- Events Alerts Reports Events Navigation \u2013 Monitor -> Events Events are Datamotive server or user generated incidents which are generated automatically when they occur. There are 4 types of Events - Information This are events occurred just for the information Warning This are events occurred to take precautionary action Error This are events occurred when there is an issue and needs to be addressed Critical This are events occurred when there is an issue and that needs to be addressed at the earliest To see \u201cEvents\u201d , go to \u201cMonitor\u201d option and click on \u201cEvents\u201d In events, the following information is displayed \u2013 Date The date and time when the event has occurred Topic The topic of the event Level The level of the event occurred (Ex. Information, warning, Error, Critical) Event type the type of the event occurred Description A short description about the event occurred User User who initiated the event Alerts Navigation \u2013 Monitor -> Alerts Alerts are Datamotive server generated warning messages based on the events and are tagged with the severity level they occur. The severity of the alerts is of 4 types - Information These are events for the information Warning These are events which require taking precautionary measures Error These are events which require user attention to address the issue Critical These are events which require immediate user attention to address the issue In Alerts, the following information is displayed \u2013 Title The headline/short description for the alert generated Severity The condition at which the alerts are generated Created The date and time at which the alerts are generated Last updated The date and time at which the alert was checked by the Datamotive server Status The symbol representing the severity of the alert When we click on the Title or Status of a particular alert a window will pop-up with a description regarding that particular alert. It consists of the 2 tabs \u2013 Info Information about the alert generated Associated Event Event associated with the generated alert The info tab consists of the following \u2013 Severity The condition at which the alerts are generated Event Type The type of event that is associated with the alert Description A short description about the event occurred Created The date and time at which the alerts are generated Updated The date and time at which the alert was checked by the Datamotive server Occurrence The frequency at which the alerts is occurred Acknowledge Message User inputs when the alert is addressed The associated event consists of the following \u2013 Event ID The ID of the event associated with the alerts Level The level of the event occurred (Ex. Information, warning, Error, Critical) Topic The topic of the event Date The date and time when the event has occurred Event Type The type of the event occurred Description A short description about the event occurred Acknowledge Message User inputs when that event is addressed User can perform specific action (system generated) or just acknowledge the alert without taking any action. Certain Alerts, mandate user action to resolve the issue. Once the alert is acknowledged or action is taken by the system, the status of the Alert changes. Reports Navigation \u2013 Monitor -> Report Datamotive provides mechanism to generate Reports listing Nodes, Events, Alerts or Jobs in the system. To generate reports, go to \u201cMonitor\u201d Tab and click on \u201cReports\u201d option- To generate a Report, click on \u201cFilter\u201d option. Reports can be gene Script will run before Datamotive executes recovery workflow for a VM when configured as a VM pre-script and before recovery of protection plan when configured as Protection Plan pre-script. Typically, this script should take care of infrastructure configurations required for the virtual machine to come up. E.g. configuring firewall rules for this VM, creating domains for authentication etc. rated for 2 types \u2013 Overall System data, all the system data is included in the report Protected Plans, selected protection plan data is included in the report. Click on the components which you want to include in the report. For Protection plan dropdown select if you want to include all protection plan details in the report. Or select a specific plan whose report is required. Once the options are selected, click on \u201cGenerate Report\u201d for the report to be generated. Click on export button to export data to .PDF format. Settings To configure your environment, you can use settings section. Settings section will allow you to configure email, Bandwidth throttling, license, and tech support. License Location: Home \u2014> Settings \u2014> License License is required to perform the recovery and migrations operations. By default, system will provide a trial license which has a fixed number of migrations and recoveries allowed. Once you perform any migration or recovery operation the respective consumption will reflect in its associated consumption bar. License installation For new license installation, contact the support@datamotive.io with following information. Node Key: You can get node key through the about section of the application. Along with node key provide the details requested by the support team. On successful credential validation Datamotive team will provide you a license file. Once you receive the license form the Datamotive team, navigate to the settings \u00e0 license Click on +New button to install the received license. A new modal window will popup. Click on the upload icon to select the license file. Post successful validation the detail of the license is shown. If all the license details look good, then click install. New license will get install in the system. If multiple license available in the system, click on the action button to active or deactivate the license. Scripts Location: Home \u2014>Settings \u2014>Scripts Datamotive supports executing custom scripts on recovery of individual virtual machine and complete protection plan as well. Datamotive supports both, Pre & Post scripts. The scripts are executed on the Datamotive management node. To configure new script, follow below steps. Click on the +New button, new popup will be shown to configure script. Select the script file for the upload Select Pre or Post script type Pre : Script will run before Datamotive executes recovery workflow for a VM when configured as a VM pre-script and before recovery of protection plan when configured as Protection Plan pre-script. Typically, this script should take care of infrastructure configurations required for the virtual machine to come up. For example, configuring firewall rules for this VM, creating domains for authentication etc. Post : Script will run after the entity is recovered when configured as VM post-script and after Protection Plan recovery when configured as Protection Plan post-script. Typically, this script should take care of recovered entity specific configurations. For example. Configuring application properties with new internal IPs etc. Scripts Input: Currently, Datamotive supports only shell scripts for execution. In future, binding for different languages will be provided. On invocation the script is provided with following parameters in the order. Pre-script: \\<None> Post-script: JSON string with following format { [ { \u201cName\u201d: \\<VM Name>, \u201cIP\u201d: \\<Newly assigned IP address of recovered VM>, \u201cUsername\u201d: \\<Login username of the recovered VM>, \u201cPassword\u201d: \\<Login password of the recovered VM> } ] } Scripts Output : The scripts are checked for it\u2019s completion and the process exit status is captured. If there are no errors in executing the script, Datamotive considers it to be successfully executed. If there are errors, the recovery is marked as Partially Completed. Provide some short description about the script (optional) <!-- --> Enter logged in user password and click Save button Post successful validation script will get uploaded and can be used in protection plan for pre or post script Following actions are available for a uploaded script. Edit: Click on edit icon to edit script. Remove: Click on remove icon to remove script. Email Location: Home \u2014>Settings \u2014> Email Email setting allow you to configure the email and recipients details so that Datamotive can send you the critical alerts details over the email. Configuration. Click on the Configure now to open email configuration window. Provide the required details and click Configure. Email Address Email address used to send the communication alerts. Email Password Email Password for the authentication. Note: System will encrypt these details before saving them in the database. SMTP Host SMTP hostname or SMTP server IP address SMTP Port SMTP port number SSL Certificate Verification Click if your smtp server is secure and SSL certificate is installed on it. Replicate Configuration If multiple sites were already connected to the node from where you are configuring the email and you want same settings should get replicate on all the connected sites, then enable this option. Post email Configuration you can view the configured details along with Email Recipients section get enabled. To add new recipient, click on +New icon Provide email address of the recipient Select the events for which you want to send email to recipients. Click configure to add new recipient in the email list for subscribed events. Using action options, you can reconfigure the recipient's details or can delete them from the list. Roles Location: Home \u2014>Settings \u2014>Roles Privileges define rights to perform action on an entity of Datamotive. Whereas the role is a set of privileges. Roles are assigned to the user. By default, Datamotive generate following three roles. administrator: With Super Admin role, user can view and perform all the available operations in the system DRadmin: With DR Admin role, user can perform operations related to protection plan and recovery/migration Guest: Read-only user can view all available views but can\u2019t perform any operation. On Left side grid all roles are listed. Click on the role o load its associated privileges and users. Users Location: Home \u2014>Settings \u2014>Users Users lists provide all registered users with their assign roles. Tech Support Location: Home \u2014>Settings \u2014>Tech Support Support bundle is useful to triage the any issue occurred in the system. To collect new support bundle, follow below steps. Click on the +Generate button, new popup will be shown to trigger bundle creation. Provide a proper description specifying why new support bundle generation is requested and click Generate Bundle Post system accepts the generate bundle request it will collect all the required info from the node. Note: This operation may take several minutes complete, you can check the status of bundle in the list. (Click Refresh to update the status) Once support bundle generation completed, in the action section you will get a download icon. Use Download icon to download the support bundle Use delete icon to remove the support bundle from the system Throttling Location: Home \u2014>Settings \u2014> Throttling Throttling allows you the configure the network usage as per requirement. By default, system will use networks full capacity to download or upload the replication data across the sites. If you want to restrict the bandwidth, use then bandwidth throttling configuration is required. Provide the below details and click configure to apply bandwidth throttling. Enable Limit Enable the option if bandwidth throttling is required. Once enable you can provide the bandwidth usage details by scrolling the usage bar or by entering the values in the usage field. Enable Time Limit If time limit base usage configuration required, then enable the option. Once enable you can provide the bandwidth limits along with its start and end time specification over which time base limits will be applicable. Apply To All Replication Nodes If you want to apply same setting on all the replication nodes, then enable this option. If you want to configure each replication node bandwidth throttling, then click on icon to configure the node specific usage limits. New popup window will be shown to configure the node specific configuration. Provide the details and click configure. Provided configuration will get applied on the node. Troubleshooting Replication Failures Snapshot Creation Failed Error: Snapshot Creation Failed Impact: Replication fails for all disks of the VM Resolution: Locate the VM in protected infrastructure using the console (AWS Console, GCP Console, vCenter Server) & Delete all snapshots named \u201cDM_REPL_SNAP\u201d. Error while attaching Volume Error: Error while attaching volume Impact: Replication fails for all disks of the VM Resolution: In case the recovery site is AWS or GCP and during protection of VM IOPs are specified, then based on the conditions specified by the cloud provider, the IOPs value may need to be altered. VM not found Error: VM not found Impact: Replication fails for all disks of the VM Resolution: This error happens when a protected virtual machine is renamed. Datamotive detects this change and generates an alert but doesn\u2019t update it\u2019s records unless user takes specific action against that alert. Subsequent replication iterations of the VM keep failing. To resolve this issue. locate the Alert corresponding to given VM and \u201cTake Action\u201d on it. It will open up Edit Protection Plan wizard which should be completed. Once the protection plan is successfully edited, the VM\u2019s replication should start again. Replication failed in GCP Error: Replication failed. *** Quota 'SSD_TOTAL_GB' exceeded. *** Impact: Replication fails for all disks of the VM Resolution: Check your SSD quota configured for the project where the Recovery site is configured. The protected VMs are configured to use either Balanced or SSD type of disks and quota in the project is reached. Either free up the space or change the disk type of protected entities to \u201cStandard\u201d. AWS: Instance |Unable to connect to server Error: Unable to connect to server Impact: Instance replication will not start Resolution: This happens when there is communication problem between the source VM and the Management servers. Please allow the required ports on the management servers and the nodes as mentioned in the deployment Guide. Deployment Guide reference - Deployment Guide Protection Plan Failures Edit Protection Plan Failed Error: VM not found Impact: Protection Plan cannot be edited Resolution: This error can occur when one or more VMs in the protection plan have configuration changes for which user has not taken any action on. To resolve this issue, close the edit protection plan wizard. Go to Alerts section and make sure that you take action on all alerts for VMs within that protection plan. Each action will take ensure the VM\u2019s data is synced with Datamotive. Once all the VMs are updated, then edit protection plan should work as expected. AWS Instance | Failure during the pplan creation Impact : Not able to create pplan Error : Fetch Network details failed:UnauthorizedOperation: You are not authorized to perform this operation.\\n\\tstatus code:403,request id***** Resolution: Please check the permissions for the IAM user as mentioned in the Deployment Guide Deployment Guide reference - Deployment Guide Recovery Failures AWS: Instance not reachable | Check Instance timed out Error: Instance timed out Impact: Instance is not recovered. \u00bd checks pass for AWS Resolution: This error occurs when protected VM doesn\u2019t meet the supported OS criteria. For details, please refer to section Support Matrix in this document. Windows disks are offline Error: After successful recovery of Windows VMs, disks other than the boot disk are found offline Impact: Applications/data if deployed/present on disks other than the boot disks are not accessible. Resolution: This error occurs in case of Windows VMs with multiple disks having disk policy configured as Offline. Edit the disk policy in recovered VMs and configure it to \"OnlineALL\". Reference URL to check the Disk Policy- https://support.purestorage.com/Solutions/Microsoft_Platform_Guide/Multipath-IO_and_Storage_Settings/Disk_Policy_Configuration_-_SAN_Policy Upgrade The upgrade feature is used to upgrade the Datamotive services, features and the Datamotive UI files. Note - Below steps needs to be done from the Management server only for server as well as nodes. Steps to upgrade the Datamotive Server and the node: Copy the \u201c DM_UPGRADE_ \\<version>.tar.gz \u201d bundle/package to the Management server via Win-scp tool /scp command or any other tool Make sure you give the read permissions to other groups for this uploaded tar bundle Command for changing file permission: Chmod 755 {UPGRADE_PACKAGE_LOCATION} Once the package is uploaded to the server, go to /bin directory using the below command - cd /opt/dmservice/bin We will use the dmcli to upgrade the Datamotive Management server and the node. In /bin directory, enter command the below command \u2013 ./dmcli --help (The above command will show you the available commands in the dmcli option as per the below snip) Command to upgrade the Datamotive Server and nodes \u2013 ./dmcli upgrade --username Administrator --path \\<path of the upgrade package> Command details \u2013 --upgrade: this parameter is used to upgrade the services/features and the UI files --username : Username to login to management server. By default its Administrator --path : Path is absolute path where you have uploaded .tar.gz ( DM_UPGRADE_\\<version>.tar.gz ) bundle on current management server Eg. If the Datamotive Upgrade file ( DM_UPGRADE_\\<version>.tar.gz ) is uploaded to /home/centos location, then the command would be \u2013 ./dmcli upgrade \u2013path /home/centos/DM_UPGRADE_1-0.tar.gz \u2013username Administrator After the successful upgrade of the server and the node, success message would be displayed as per the below snip-","title":"User Guide"},{"location":"#_1","text":"","title":""},{"location":"#introduction","text":"Datamotive Workload Mobility product suite delivers a disaster recovery and workload migration service and offers cloud economics to help keep your disaster recovery and migration costs under control. Datamotive Workload Mobility can be used to protect your vSphere virtual machines by replicating them periodically to the cloud and recovering them as needed to a target public cloud platform as a native cloud instance (E.g., protected virtual machine is recovered as a native AWS EC2 instance or a GCP Compute instance). The Datamotive Replication Engine replicates the entire protected VM over to the target platform. This includes the OS, the OS configuration, the registry entries, application and application data, everything inside the VM is replicated. The first replication iteration is a full copy of the VM from the source environment to the target cloud platform. Following iterations, only replicate the changed data from the previously successfully completed replication iterations. Datamotive does not require or need any agents to be deployed or installed on the protected VMs. Each VM is completely treated as a black box by Datamotive. As a result, the enterprises workloads (VMs) require no operational management, nor require any special security configurations. There is also minimal performance impact on the business applications. The Datamotive Replication Engine also enables near instantaneous recovery of the workloads in the target cloud platforms. When the workloads are recovered or migrated in the cloud, they are already in the native cloud platform (AWS EC2 instance or GCP Compute instance formats). No additional conversion or rehydration or seeding is required. Datamotive provides an unprecedented Recovery Time Objective (RTO) of 10 minutes per protected virtual machine. Similarly provided, in the case of Migration, is a Cutover Time Objective (CTO) of 10 minutes per VM with zero data loss. The Datamotive platform currently provides and supports Disaster Recovery and Migration use-cases. Very soon, Datamotive will also be providing and supporting Ransomware Recovery and Rapid Dev/Test Deployments (Cloud Cloning) use-cases. a","title":"Introduction"},{"location":"#_2","text":"","title":""},{"location":"#datamotive-component-architecture","text":"Datamotive Replication Service \u2013 a virtual appliance installed in the VMware vSphere environment where the virtual machines to be protected are running under normal circumstances. This appliance also presents a user interface (UI), a CLI and REST APIs for the IT administrators to use under normal circumstances. Datamotive Cloud Service \u2013 a virtual appliance deployed in the public cloud environment (AWS or GCP) where the protected virtual machines will be recovered in the event of a disaster or when VMs are migrated to the target public cloud. This appliance also presents a user interface (UI), a CLI and REST APIs for the IT administrators to use in the event of a disaster and the on-premises Datamotive Replication Service is un-available. Migration and Recovery jobs can be triggered using this interface. Datamotive Prep Appliance \u2013 a Windows virtual appliance deployed in the public cloud environment (AWS or GCP). This appliance is only powered-on and used when recovering or migrating Windows VMs. Capabilities and Benefits Datamotive Workload Mobility provides the following key capabilities: Hybrid, Multi Cloud Simplicity \u2013 Provides comprehensive SaaS simplicity across on-demand Disaster Recovery, Migration and Ransomware Recovery Agentless Model \u2013 Datamotive requires no agents on the protected VMs, leading to significantly simpler management of VMs under normal circumstances. Minimal performance impact on the protected VMs as compared to agent-based solutions and most importantly, no need to open additional (or per protected VM) ports in your firewall. Follow your Zero Trust Security policies completely. Industry Best SLAs \u2013 Datamotive provides 10 minutes or less RTO or CTO regardless of the size of the workload. If your VMs/workloads are 100 GB or 2 TB, Datamotive will always take 10 minutes or less to completely recover them in the cloud. Cost Optimized \u2013 Reduce your capex and opex significantly by leveraging the economics and pay-per-use model of public clouds. Only pay for cloud storage costs. Pay for compute and network only when a disaster strikes, and your workloads are recovered in the cloud. Unlimited Test Recovery \u2013 Execute Test Recovery workflows in a network fenced environment to test your replication consistency safely and securely. Ransomware Recovery \u2013 Protect your workloads from cybercrime attacks by keeping point-in-time copies in air-gapped, low-cost public cloud storage. In the event of an attack, choose the latest copy and recover your workloads in the cloud in minutes.","title":"Datamotive Component Architecture"},{"location":"#support-matrix","text":"","title":"Support Matrix"},{"location":"#vmware","text":"vCenter Server 5.5 vCenter Server 6.0 vCenter Server 6.5 (U1, U2) vCenter Server 6.5 (U3) vCenter Server 6.7 vCenter Server 6.7 (U1, U2, U3) vCenter Server 7.0 ESXi 5.5 ESXi 6.0 ESXi 6.5 (GA, U1, U2) ESXi 6.5 (U3) ESXi 6.7 (GA, U1, U2) ESXi 7.0 (GA)","title":"VMware"},{"location":"#cloud-providers","text":"Following are the supported public cloud providers. AWS (Amazon Web Services) Google Cloud","title":"Cloud Providers"},{"location":"#guest-os","text":"OS Kernel Version Support CentOS 6 - CentOS 7.9 3.10.0-1160.el7.x86_64 CentOS 8 - Red Hat Enterprise Linux 6 - Red Hat Enterprise Linux 7.9 3.10.0-1160.el7.x86_64 Red Hat Enterprise Linux 8 - Ubuntu 14 4.4.0-148-generic Ubuntu 16 4.15.0-45-generic 4.15.0-142-generic 4.10.0-28-generic Ubuntu 18 5.4.0-42-generic, 5.4.0-72-generic 5.4.0-91-generic Ubuntu 20 5.11.0-27-generic Oracle Linux 6 - Oracle Linux 7 - Oracle Linux 8 - Debian 9 - Debian 10 - Suse Linux 12 - Suse Linux 15 - Microsoft Windows 10 Professional MS Windows Server 2012 (Standard, Datacenter) Reverse recovery for Win2k12 is currently not supported to VMWare (specifically for VMWare to AWS) MS Windows Server 2012-R2 (Standard, Datacenter) Reverse recovery for Win2k12-R2 is currently not supported to VMWare (specifically for VMWare to AWS) MS Windows Server 2016 (Standard, Datacenter) MS Windows Server 2019 (Standard, Datacenter)","title":"Guest OS"},{"location":"#supported-browser-versions","text":"Browser Names Versions Mozilla Firefox 98.0.2 (64-bit) Google Chrome Version 99.0.4844.82 (Official Build) (64-bit)","title":"Supported Browser Versions"},{"location":"#_3","text":"","title":""},{"location":"#_4","text":"","title":""},{"location":"#_5","text":"","title":""},{"location":"#authentication","text":"Open the Datamotive UI through URL: \\< Datamotive_Service_IP >:5000 Provide the username and password and press Login On successful login, User will see the Datamotive Dashboard. By default Datamotive will create following three users Administrator DRadmin Guest Default password for all the users is \u2018admin\u2019 Note: If you are login first time then for security reasons password change is must. Provide the current password and new password. Click on change password button to set new password for the system.","title":"Authentication"},{"location":"#dashboard","text":"The Dashboard provides you with an at-a-glance overview of the data protection status of your environment. The Dashboard contains the following features.","title":"Dashboard"},{"location":"#title-windows","text":"Title windows will give overall status on your configured and protected environment. Title Description Sites Sites configured on the node. Protection Plans Protection plans configured. Protected Machines Total number of protected virtual machines Storage Overall protected storage size.","title":"Title Windows"},{"location":"#alert-statistics","text":"Active alter which needs a user action acknowledgement or action on it.","title":"Alert Statistics"},{"location":"#_6","text":"","title":""},{"location":"#rpo-and-rto-statistics","text":"Current recovery time objective and recovery point objective. Title Description RPO Average recovery point objective value RTO Average of recovery time object value Test Executions Test executions completed successfully. Full Recovery Virtual machines recovered successfully. Migrations Virtual machines migrated successfully.","title":"RPO and RTO Statistics"},{"location":"#_7","text":"","title":""},{"location":"#replication-statistics","text":"Replication statistics provides a central snapshot overview of your protected environment replication jobs. Label Description Completed Successfully completed replication iterations. Running Replication iterations are in-progress. Failed Failed replication iterations. Change Rate Average data change rate for all protected virtual machines Data Reduction Average percentage of data reduction for all the completed replications.","title":"Replication Statistics"},{"location":"#jobs","text":"Jobs shows the recently started or completed task in the system.","title":"Jobs"},{"location":"#_8","text":"","title":""},{"location":"#virtual-machine-protection-analysis","text":"Virtual machine protection analysis shows the overall status of recovery site environment in terms of total discovered virtual machines with percentage of protected and unprotected virtual machines. In addition to protection analysis, this wizard also provides the details for replication statistics of virtual machines which are in-sync and not in-sync.","title":"Virtual Machine Protection Analysis"},{"location":"#_9","text":"","title":""},{"location":"#bandwidth-usage","text":"Bandwidth usage provide the details network usage of the system for last 12 hours. The bandwidth usage chart shows data downloaded and uploaded for last 12 hours.","title":"Bandwidth Usage"},{"location":"#_10","text":"","title":""},{"location":"#site-connections","text":"Provides connection details of configured sites in terms of data flow i.e., from which source site data replication is configured for target site.","title":"Site Connections"},{"location":"#events","text":"Events are records of user actions or system actions that occurred in the Datamotive system. The Events widget provides most recent 5 events generated in the system.","title":"Events"},{"location":"#nodes-configuration","text":"Nodes are entities where the Datamotive server is installed (Ex. AWS, GCP, VMWare, etc.). Datamotive Nodes are of different types wiz Management, Replication, Dedup & Win Prep. Each node has specific functionality. Management: Node for performing Datamotive management operations. There must be one and only Management node for each site. Replication: Nodes responsible for performing replication activities. These can be added based on number of Virtual Machine disks to be replicated in parallel. Any number of nodes can be added to meet the requirement. Dedup: This is a special type of node required to support deduplication. This node is required only on the Recovery site. Win Prep: This is also a special type of node required only on Recovery site to perform Windows workloads recovery. For all the nodes, Datamotive provides separate OVAs & cloud specific machine images. Once Node of given type is deployed in the infrastructure, it needs to be added in the Datamotive Management server. Nodes must be deployed and configured in following manner. Management Node: Deploy 1 management node per protected site. Local node representing the management node automatically gets registered. Remote Management Node: Deploy 1 management node per recovery site. Register the management nodes from Recovery Sites in Management Node of Protected Site. Replication Nodes: Deploy replication node based on load. Once deployed register replication node in the local management server. Replication nodes are always added to local management node only. Dedup Node: Deploy the Dedup node on Recovery Site. Once deployed, register the Dedup node with Management Node on the Recovery Site. Win Prep Node: Deploy the Win Prep node on Recovery Site. Once deployed, register the Win Prep node with Management Node on the Recovery Site. To Access Node option, Go to Configure -> Nodes (Note- By default the Local node will be configured.) To add new node - Click On \u201c+ New \u201d option as shown below - It consists of the below options- Name The desired name to identification Hostname This is FQDN or IP address of the server Username This is the username of the Datamotive Engine Password This is the password of the Datamotive Engine Type The type of Datamotive server which is being added. Type consists of 4 options - Management, Replication, Prep Node and Dedupe Server In Type select the appropriate option from the drop down - Type Description Management Used when you would want to manage the servers (Edit, remove, and modify, etc) Replication Used when you would want to replicate the servers to the target site Prep Node Prep Node is used when you would want to recover the Windows server Dedupe Server Used for de-duplication of data (Note \u2013 Based on the selection of Type, further details need to be entered). Ex. In option, the management type is selected. It consists of the below options - Platform Type Platform where the node is deployed Management port Port on which the management service runs (By default, it 5000) Replication Data Port Port on which the replication data service runs (By default, it 5001) Replication Controller Port Port on which the replication controller service runs (By default, it 5003) Encryption Key Data will be encrypted using this key while transferring from one node to another node. The key for the node can be accessed in the remote management node, under the node configuration section. Once the details are entered click on Configure option.","title":"Nodes Configuration"},{"location":"#sites-configuration","text":"Sites are environment setup for Protection plan to configure. Site consists of platform type and platform details. In the Datamotive UI, go to Configure tab on the left-hand side panel and select Sites. To do Site can be of following types: Protection - A protection site is the source of the protection plan workload replication. Recover - A Recover site is the destination for the protection plan workload replication.","title":"Sites configuration"},{"location":"#create-site","text":"To create site, click the \u201c+ New\u201d button and Create site windows will pop-up. The common inputs are- Name : Enter a desired name to identify the site Description : Short information about the site Site Type : (Protect/Recover) - Select the site type based on source or destination. Platform Type : Select the Platform type - VMware/AWS/GCP. Node : Select the node based on the Platform type where the workloads are hosted (Note: Based on the platform type and node the options change) Platform Type: VMWare: - vCenter Server IP: Enter the vCenter Server IP address where the workloads are hosted Port : By default, 443 Username : Enter the vCenter Server username Password : Enter the password for vCenter user AWS: - Region : Select the desired region where the workloads will be replicated/recovered Zone : Select the desired zone in the region where the workloads will be replicated/recovered Access Key : AWS User Access Key Secret Key : AWS User Secret Key GCP: - Region : Select the desired region where the workloads will be replicated/recovered Zone : Select the desired zone in the region where the workloads will be replicated/recovered Project ID : Enter the project id from the GCP console Click on configure to create the site and on successful creation, site will be listed in the list view. V Center Server IP","title":"Create Site"},{"location":"#edit-site","text":"To Edit a site, click on Edit button and then Edit windows will pop-up. Edit the input which need to be changed and click on configure to save the configuration.","title":"Edit Site"},{"location":"#remove-site","text":"Click on Remove button to delete one or more sites. On click of confirm, the sites will be deleted.","title":"Remove Site"},{"location":"#protection-plan","text":"Navigation: Home \u2014> Configuration \u2014> Protection Pl Protection plan consists of a group of workloads which will be replicated from source to destination sites","title":"Protection plan"},{"location":"#create-protection-plan","text":"","title":"Create Protection Plan"},{"location":"#prerequisite","text":"VMware platform : VMware tools must be installed in all the Virtual Machines which needs to be protected. CBT (Change block tracking) must be enabled for all the Virtual Machines and their disks. To create a new protection plan, click on + New button in protection plan list, create protection plan wizard is shown. Follow the guided steps to configure protection plan.","title":"Prerequisite"},{"location":"#general","text":"Name : Desired name of the protection plan. Protect Site : Source protection site. Recovery Site : Destination recovery site.","title":"General"},{"location":"#virtual-machines","text":"Select the virtual machines to be protected and click next. Use search & pagination to find virtual machines. Recovery Configuration Provide the virtual machine specific recover configuration which will be used for creation of instance on recovery site.","title":"Virtual Machines"},{"location":"#general_1","text":"Instance Type : Instance type on cloud site - Example t2.micro on AWS or n1-standard-1 on GCP. Volume Type : Instance volume type on cloud site - Example GP-2 on AWS or standard on GCP. Volume IOPS : IOPs value for supported Volume Types. Please note that the IOPs values are submitted for volume creation without validations. Make sure that all the rules specific to selected volume type are followed while specifying the IOPs value Tags : Instance tags. Example \u2013 Tag Key \u2013 Name Tag value \u2013 dm-repl-node Network : For instance, network configuration click on config button, will open a network configuration popup window. For AWS platform as recovery site, the following configuration options are provided- VPC : Virtual Private Cloud (Amazon VPC) enables you to launch AWS resources into a virtual network that you've defined. Create from Source: This option is used when you need to copy the network configuration from the source instance. All the options like subnets, IP address and security groups get auto-filled as the source instance Subnet : subnet ID which will assigned to the instances in this protection plan. Auto Public IP : Click on the checkbox if you want to auto assign a public Ip to instance. Note - only one network card can be configured if public Ip is enabled. Elastic IP for instance : Select from allocated elastic IP address pool if any. Private IP : Provide the internal IP address for the instance or leave blank for auto assignment. (Please ensure to specify Private IP in the same range as that of given Subnet and is unique too) Security Groups : Select the security groups all configure inbound and outbound traffic for the instance. For GCP platform provided the following details Network : Network which will be assigned to the instances in the Protection Plan Subnet : subnet ID which will assigned to the instances in this protection plan. Private IP : Provide the internal IP address for the instance or leave blank for auto assignment. External IP : Select one of the following options if external Ip address is required for the selected network card else select none. 1. Auto: gcp will assign a Ip address from its public Ip pool. 2. None: select if external not required. 3. Reserved IP address, GCP project reserved Ip address, will be listed along with above two options. You can select any reserved Ip address from the list. Network Tier : Network Service Tiers lets you optimize connectivity between systems on the internet and your Google Cloud instances. Premium Tier delivers traffic on Google's premium backbone, while Standard Tier uses regular ISP networks Firewall Tags: The target tag defines the Google Cloud VMs to which the rule applies. Replication Scripts : Datamotive supports executing custom scripts for individual VM and complete protection plan as well.IT supports both, pre and post scripts. To use pre or post scripts, first upload the pre & post scripts to Datamotive management node on recovery and protection site using scripts section in settings. Once the scripts are uploaded, they will be visible in the pre and post replication scripts option - Pre \u2013 The pre script will be executed before every iteration when the replication starts. For example, you need to stop the service of a particular server before the replication starts Post - The post script will be executed after every iteration when the replication is completed. For example, you need to export the replicated data size to a particular file. Recovery Scripts : Datamotive supports executing custom scripts on recovery of individual virtual machine and complete protection plan as well. Datamotive supports both, Pre & Post scripts. The scripts are executed on the Datamotive management node. To use pre or post scripts, first upload the pre & post scripts to Datamotive management node on recovery and protection site using scripts section in settings. Once these scripts are uploaded, they will start showing up in drop down menu of scripts in create & update protection plan wizard. Once configured, the scripts will get invoked as below. Pre: Script will run before Datamotive executes recovery workflow for a VM when configured as a VM pre-script and before recovery of protection plan when configured as Protection Plan pre-script. Typically, this script should take care of infrastructure configurations required for the virtual machine to come up. For example, configuring firewall rules for this VM, creating domains for authentication etc. Post: Script will run after the entity is recovered when configured as VM post-script and after Protection Plan recovery when configured as Protection Plan post-script. Typically, this script should take care of recovered entity specific configurations. For example. Configuring application properties with new internal IPs etc. Scripts Input: Currently, Datamotive supports only shell scripts for execution. In future, binding for different languages will be provided. On invocation the script is provided with following parameters in the order. Pre-script: \\<None> Post-script: JSON string with following format { [ { \u201cName\u201d: \\<VM Name>, \u201cIP\u201d: \\<Newly assigned IP address of recovered VM>, \u201cUsername\u201d: \\<Login username of the recovered VM>, \u201cPassword\u201d: \\<Login password of the recovered VM> } ] } Scripts Output: The scripts are checked for it\u2019s completion and the process exit status is captured. If there are no errors in executing the script, Datamotive considers it to be successfully executed. If there are errors, the recovery is marked as Partially Completed.","title":"General"},{"location":"#boot-order","text":"Using boot order configuration defines the boot delay and virtual machine boot order. Boot Delay : Delay in seconds between virtual machines specified in the boot order Boot Order : Order in which virtual machines will get recovered or migrated.","title":"Boot Order"},{"location":"#replication-configuration","text":"Start Time : Time from when protection plan replication will start. Replication interval : Time interval in which the virtual machine\u2019s changed data will be replicated. Encryption On Wire : Data encryption while transferring from source to destination. Compression : Data compression while transferring from source to destination. Dedupe : Enables the data deduplication. Note: Deduplication node should be pre-configured on recovery site before using this feature. Differential Reverse Replication: Enable this feature if you want to allow recovered machines from the recovery site to replicate back to its original source site. Scripts Replication Scripts: These are scripts which would run before or after every replication iteration. Pre Script: The pre script will be executed before every iteration when the replication starts for this protection plan. Post Script- The post script will be executed after every iteration when the replication is completed for this protection plan. Recovery Scripts: This are scripts which would run before or after the recovery of the VM/instance Pre Script: Pre scripts which will run before recovery workflow for this protection plan. Post Script: Post scripts which will run after all the instances are recovered on recovery site.","title":"Replication Configuration"},{"location":"#summary","text":"Review the summary for the protection plan and click finish to configure the protection plan. On successful configuration, replication jobs will start for the virtual machines selected for this protection plan.","title":"Summary"},{"location":"#protection-plan-actions","text":"Action on protection plan is available through the protection plan list and through the protection plan details page. Action will get enable depending upon the context and state of the protection plan. Actions available through the protection plan data grid view. Actions available through the protection plan details Actions for source site Actions for recovery site New: Click to configure new protection plan. Edit: Select protection plan from the list and click edit. Edit protection plan wizard will get open. In edit protection following operations were allowed Add new virtual machine to plan. Remove protected virtual machine from the plan. This action gets completed on next successful iteration of the protection plan. The VM shows as \u201cRemoving\u201d till that time. Recovery configuration modification. Boot order configuration & modification. Replication configuration Scripts modification. Start : Start Replication for the selected protection plan. Stop: Stop the protection plan replication. Remove: To remove the protection plan, click on the Remove button and it will ask for the confirmation. On confirm, the protection plan will get deleted. Note protection plan should be in stopped state with no running jobs.","title":"Protection Plan Actions"},{"location":"#recovery","text":"To initiate recovery or migration go to Home \u2014> Configuration \u2014> Protection Plan -> Click on the protection plan on which recovery or migration operation need to perform. Click on the Actions button. All available operation will get listed.","title":"Recovery"},{"location":"#_11","text":"","title":""},{"location":"#test-recovery","text":"","title":"Test Recovery"},{"location":"#prerequisite_1","text":"At least one replication job has been completed successfully for the virtual machine and the sync status for that job should be In-synch. Virtual Machines Select the virtual machines for the test recovery. Provide the credentials to execute the pre and post scripts. If there are no scripts for the virtual machine, then credentials are not mandatory. Credentials are not stored anywhere and only been used for the workflow. NOTE: For Windows recovery on AWS, Credentials are mandatory even if there are no scripts. Recovery Configuration Install System Agents: For AWS, install OS agents like EC2Launch and SSMAgents. For GCP, install google os-config and compute-engine agents. Install Cloud Packages : For AWS. install AWS Cloud SDK and for GCP, install GCP Cloud SDK.","title":"Prerequisite"},{"location":"#_12","text":"","title":""},{"location":"#summary_1","text":"Review the summary and click on finish to start the test recovery. This will start the test recovery jobs for the selected virtual machines and jobs can be monitored in the Home \u2014> Jobs \u2014> Recovery. Test Recovery validation Check the status of the virtual machine's recovery jobs in the Home \u2014> Jobs \u2014> Recovery. Check the Cloud Console (AWS and GCP) for the instances with the virtual machines name and their running status. AWS also has status checks. On successful completion of recovery jobs, IP Address can be found for the new running instances. For Windows machines, download the RDP file by click the download button right next to the IP address and check the windows machine through RDP. For Linux machines, copy the IP address and check the linux machine through ssh. Note: Once the validations are completed, Datamotive recommends to remove the Test Recovered instance.","title":"Summary"},{"location":"#_13","text":"","title":""},{"location":"#full-recovery","text":"To perform full recovery after disaster in the source site, open Management Application on Recovery Site and go to Home \u2014> Configuration \u2014> Protection Plan \u2013> Click on the Protection plan. Click on Action button and select Recovery Prerequisite: At least one replication job has been completed successfully for the virtual machine and the sync status for that job should be init-success. Virtual Machines Select the virtual machines for the test recovery. Provide the credentials to execute the pre and postscripts. If there are no scripts for the virtual machine, then credentials are not mandatory. Credentials are not stored anywhere and only been used for the workflow. NOTE: For Windows recovery on AWS, Credentials are mandatory even if there are no scripts. Recovery Configuration Install System Agents: For AWS, install OS agents like EC2Launch and SSMAgents. For GCP, install google os-config and compute-engine agents. Install Cloud Packages : For AWS. install AWS Cloud SDK and for GCP, install GCP Cloud SDK. Recovery Summary Review the summary and click on finish to start the test recovery. This will start the test recovery jobs for the selected virtual machines and jobs can be monitored in the Home \u2014> Jobs \u2014> Recovery jobs. NOTE: If the replication job is on-going at the time of Full Recovery, then the instance will be recovered from the last known good state.","title":"Full Recovery"},{"location":"#migration","text":"To migrate the workloads, go to Home \u2014> Configuration \u2014> Protection Plan \u00e0 Click on the protection on which migration need to perform, on the Recovery site. Click on actions buttons and select Migrate Prerequisite: In case of migration, to make sure there is no loss of data, the virtual machine(s) should be in power off state and the last replication jobs should be successfully completed with zero changed data. Virtual Machines Select the virtual machines and provide the credentials if there are pre- or post-configured for these virtual machines. Note: For Windows machine in AWS, credentials are mandatory. Recovery Configuration Install System Agents: For AWS, install OS agents like EC2Launch and SSMAgents. For GCP, install google os-config and compute-engine agents. Install Cloud Packages : For AWS. install AWS Cloud SDK and for GCP, install GCP Cloud SDK.","title":"Migration"},{"location":"#_14","text":"","title":""},{"location":"#summary_2","text":"Review the summary and click on finish to start the Migration . This will start the test migration jobs for the selected virtual machines and jobs can be monitored in the Home \u2014> Jobs \u2014> Recovery jobs. Job's view after migration completed","title":"Summary"},{"location":"#jobs_1","text":"Navigation: Home --> Jobs You can use the Jobs page to monitor the overall status of replication and recovery jobs.","title":"Jobs"},{"location":"#replication","text":"The Replication Jobs tab provides details about all the running, completed, and failed replication iterations. The Replication job section has the following sub-section to show replication jobs base on the grouping criteria.","title":"Replication"},{"location":"#protection-plan_1","text":"Navigation: Home --> Jobs --> Select Protection Plan. Protection plan replication details provide a list of protection plans. Each protection plan has its associated virtual machine replication information. click icon or title to view protection plan level details. Column Name Description Name Name of virtual machine associated with the protection plan. Iteration The total number of replication iterations completed. Total Changed Total data changed. Total Transferred Total data transferred to the replication server. Data Reduction (%) Overall data reduction. Job Status Status of latest replication iteration. Completed : Replication was completed successfully. Started : Replication is running. Partially Completed : Replication completed with errors. Failed : Replication failed. Sync Status Virtual machine sync status. Init-success : The first iteration completed successfully. Init-in-progress : The first iteration is running. Init-failed : The first iteration failed. In-sync : Iteration is completed within configured replication interval time. Exceeded interval : Iteration is completed but took more time than configured replication interval time. Sync-failed : Replication iteration failed.","title":"Protection Plan"},{"location":"#virtual-machines_1","text":"Provides a list of replication details for each protected virtual machine. Note: For failed jobs, hover on the Sync Status column to get details of the status. Hover on the Replication Duration column to get Replication start & end time. Column Name Description Virtual Machine Name of the protected virtual machine. Iteration Total number of replication iterations completed. Changed Total changed data discovered. Transferred Total data transferred to the replication server. Replication Duration Time took to complete iteration. Job Status Status of replication iteration. Sync Status Virtual machine sync status.","title":"Virtual Machines"},{"location":"#disks","text":"Provide a list of replication details for each protected virtual machine disk/volume. Column Name Description Virtual Machine Name of the protected virtual machine. Disk Id Disk id of virtual machine. Data Changed Total changed data discovered for the disk. Data Transferred Total data transferred to the replication server. Replication Duration Time took to complete iteration. Job Status Status of replication iteration.","title":"Disks"},{"location":"#recovery-jobs","text":"The Recovery jobs tab provides details about all the running, completed and failed recovery operations.","title":"Recovery Jobs"},{"location":"#protection-plan_2","text":"Protection plan recovery details provide a list of protection plans. Each protection plan has its associated recovered (Full / Test) or migrated virtual machine information. click icon or title to view protection plan level details. Column Name Description Name Name of virtual machine associated with the protection plan. Duration The time required to complete the recovery. Recovery Type Recovery Type (Full Recovery, Test Recovery or Migration) Status Recovery/Migration status.","title":"Protection Plan"},{"location":"#virtual-machines_2","text":"Provides a list of recovered (Test/Full) or migrated virtual machines. Column Name Description Virtual Machine Name of virtual machine. Duration The time required to complete the recovery/migration. Recovery Type Recovery Type (Full Recovery, Test Recovery or Migration) Job Status Recovery job status. Completed : Recovery completed successfully. Started : Recovery job is running. Partially Completed : Recovery completed with errors. Failed : Recovery failed. IP Address Recovered virtual machine IP address.","title":"Virtual Machines"},{"location":"#monitor","text":"Monitor Option is used to see the events, alerts and customized reports as they are generated. In Monitor, there are 3 options- Events Alerts Reports","title":"Monitor"},{"location":"#events_1","text":"Navigation \u2013 Monitor -> Events Events are Datamotive server or user generated incidents which are generated automatically when they occur. There are 4 types of Events - Information This are events occurred just for the information Warning This are events occurred to take precautionary action Error This are events occurred when there is an issue and needs to be addressed Critical This are events occurred when there is an issue and that needs to be addressed at the earliest To see \u201cEvents\u201d , go to \u201cMonitor\u201d option and click on \u201cEvents\u201d In events, the following information is displayed \u2013 Date The date and time when the event has occurred Topic The topic of the event Level The level of the event occurred (Ex. Information, warning, Error, Critical) Event type the type of the event occurred Description A short description about the event occurred User User who initiated the event","title":"Events"},{"location":"#alerts","text":"Navigation \u2013 Monitor -> Alerts Alerts are Datamotive server generated warning messages based on the events and are tagged with the severity level they occur. The severity of the alerts is of 4 types - Information These are events for the information Warning These are events which require taking precautionary measures Error These are events which require user attention to address the issue Critical These are events which require immediate user attention to address the issue In Alerts, the following information is displayed \u2013 Title The headline/short description for the alert generated Severity The condition at which the alerts are generated Created The date and time at which the alerts are generated Last updated The date and time at which the alert was checked by the Datamotive server Status The symbol representing the severity of the alert When we click on the Title or Status of a particular alert a window will pop-up with a description regarding that particular alert. It consists of the 2 tabs \u2013 Info Information about the alert generated Associated Event Event associated with the generated alert The info tab consists of the following \u2013 Severity The condition at which the alerts are generated Event Type The type of event that is associated with the alert Description A short description about the event occurred Created The date and time at which the alerts are generated Updated The date and time at which the alert was checked by the Datamotive server Occurrence The frequency at which the alerts is occurred Acknowledge Message User inputs when the alert is addressed The associated event consists of the following \u2013 Event ID The ID of the event associated with the alerts Level The level of the event occurred (Ex. Information, warning, Error, Critical) Topic The topic of the event Date The date and time when the event has occurred Event Type The type of the event occurred Description A short description about the event occurred Acknowledge Message User inputs when that event is addressed User can perform specific action (system generated) or just acknowledge the alert without taking any action. Certain Alerts, mandate user action to resolve the issue. Once the alert is acknowledged or action is taken by the system, the status of the Alert changes.","title":"Alerts"},{"location":"#reports","text":"Navigation \u2013 Monitor -> Report Datamotive provides mechanism to generate Reports listing Nodes, Events, Alerts or Jobs in the system. To generate reports, go to \u201cMonitor\u201d Tab and click on \u201cReports\u201d option- To generate a Report, click on \u201cFilter\u201d option. Reports can be gene Script will run before Datamotive executes recovery workflow for a VM when configured as a VM pre-script and before recovery of protection plan when configured as Protection Plan pre-script. Typically, this script should take care of infrastructure configurations required for the virtual machine to come up. E.g. configuring firewall rules for this VM, creating domains for authentication etc. rated for 2 types \u2013 Overall System data, all the system data is included in the report Protected Plans, selected protection plan data is included in the report. Click on the components which you want to include in the report. For Protection plan dropdown select if you want to include all protection plan details in the report. Or select a specific plan whose report is required. Once the options are selected, click on \u201cGenerate Report\u201d for the report to be generated. Click on export button to export data to .PDF format.","title":"Reports"},{"location":"#settings","text":"To configure your environment, you can use settings section. Settings section will allow you to configure email, Bandwidth throttling, license, and tech support.","title":"Settings"},{"location":"#_15","text":"","title":""},{"location":"#license","text":"Location: Home \u2014> Settings \u2014> License License is required to perform the recovery and migrations operations. By default, system will provide a trial license which has a fixed number of migrations and recoveries allowed. Once you perform any migration or recovery operation the respective consumption will reflect in its associated consumption bar.","title":"License"},{"location":"#license-installation","text":"For new license installation, contact the support@datamotive.io with following information. Node Key: You can get node key through the about section of the application. Along with node key provide the details requested by the support team. On successful credential validation Datamotive team will provide you a license file. Once you receive the license form the Datamotive team, navigate to the settings \u00e0 license Click on +New button to install the received license. A new modal window will popup. Click on the upload icon to select the license file. Post successful validation the detail of the license is shown. If all the license details look good, then click install. New license will get install in the system. If multiple license available in the system, click on the action button to active or deactivate the license.","title":"License installation"},{"location":"#scripts","text":"Location: Home \u2014>Settings \u2014>Scripts Datamotive supports executing custom scripts on recovery of individual virtual machine and complete protection plan as well. Datamotive supports both, Pre & Post scripts. The scripts are executed on the Datamotive management node. To configure new script, follow below steps. Click on the +New button, new popup will be shown to configure script. Select the script file for the upload Select Pre or Post script type Pre : Script will run before Datamotive executes recovery workflow for a VM when configured as a VM pre-script and before recovery of protection plan when configured as Protection Plan pre-script. Typically, this script should take care of infrastructure configurations required for the virtual machine to come up. For example, configuring firewall rules for this VM, creating domains for authentication etc. Post : Script will run after the entity is recovered when configured as VM post-script and after Protection Plan recovery when configured as Protection Plan post-script. Typically, this script should take care of recovered entity specific configurations. For example. Configuring application properties with new internal IPs etc. Scripts Input: Currently, Datamotive supports only shell scripts for execution. In future, binding for different languages will be provided. On invocation the script is provided with following parameters in the order. Pre-script: \\<None> Post-script: JSON string with following format { [ { \u201cName\u201d: \\<VM Name>, \u201cIP\u201d: \\<Newly assigned IP address of recovered VM>, \u201cUsername\u201d: \\<Login username of the recovered VM>, \u201cPassword\u201d: \\<Login password of the recovered VM> } ] } Scripts Output : The scripts are checked for it\u2019s completion and the process exit status is captured. If there are no errors in executing the script, Datamotive considers it to be successfully executed. If there are errors, the recovery is marked as Partially Completed. Provide some short description about the script (optional) <!-- --> Enter logged in user password and click Save button Post successful validation script will get uploaded and can be used in protection plan for pre or post script Following actions are available for a uploaded script. Edit: Click on edit icon to edit script. Remove: Click on remove icon to remove script.","title":"Scripts"},{"location":"#email","text":"Location: Home \u2014>Settings \u2014> Email Email setting allow you to configure the email and recipients details so that Datamotive can send you the critical alerts details over the email. Configuration. Click on the Configure now to open email configuration window. Provide the required details and click Configure. Email Address Email address used to send the communication alerts. Email Password Email Password for the authentication. Note: System will encrypt these details before saving them in the database. SMTP Host SMTP hostname or SMTP server IP address SMTP Port SMTP port number SSL Certificate Verification Click if your smtp server is secure and SSL certificate is installed on it. Replicate Configuration If multiple sites were already connected to the node from where you are configuring the email and you want same settings should get replicate on all the connected sites, then enable this option. Post email Configuration you can view the configured details along with Email Recipients section get enabled. To add new recipient, click on +New icon Provide email address of the recipient Select the events for which you want to send email to recipients. Click configure to add new recipient in the email list for subscribed events. Using action options, you can reconfigure the recipient's details or can delete them from the list. Roles Location: Home \u2014>Settings \u2014>Roles Privileges define rights to perform action on an entity of Datamotive. Whereas the role is a set of privileges. Roles are assigned to the user. By default, Datamotive generate following three roles. administrator: With Super Admin role, user can view and perform all the available operations in the system DRadmin: With DR Admin role, user can perform operations related to protection plan and recovery/migration Guest: Read-only user can view all available views but can\u2019t perform any operation. On Left side grid all roles are listed. Click on the role o load its associated privileges and users. Users Location: Home \u2014>Settings \u2014>Users Users lists provide all registered users with their assign roles.","title":"Email"},{"location":"#tech-support","text":"Location: Home \u2014>Settings \u2014>Tech Support Support bundle is useful to triage the any issue occurred in the system. To collect new support bundle, follow below steps. Click on the +Generate button, new popup will be shown to trigger bundle creation. Provide a proper description specifying why new support bundle generation is requested and click Generate Bundle Post system accepts the generate bundle request it will collect all the required info from the node. Note: This operation may take several minutes complete, you can check the status of bundle in the list. (Click Refresh to update the status) Once support bundle generation completed, in the action section you will get a download icon. Use Download icon to download the support bundle Use delete icon to remove the support bundle from the system","title":"Tech Support"},{"location":"#throttling","text":"Location: Home \u2014>Settings \u2014> Throttling Throttling allows you the configure the network usage as per requirement. By default, system will use networks full capacity to download or upload the replication data across the sites. If you want to restrict the bandwidth, use then bandwidth throttling configuration is required. Provide the below details and click configure to apply bandwidth throttling. Enable Limit Enable the option if bandwidth throttling is required. Once enable you can provide the bandwidth usage details by scrolling the usage bar or by entering the values in the usage field. Enable Time Limit If time limit base usage configuration required, then enable the option. Once enable you can provide the bandwidth limits along with its start and end time specification over which time base limits will be applicable. Apply To All Replication Nodes If you want to apply same setting on all the replication nodes, then enable this option. If you want to configure each replication node bandwidth throttling, then click on icon to configure the node specific usage limits. New popup window will be shown to configure the node specific configuration. Provide the details and click configure. Provided configuration will get applied on the node.","title":"Throttling"},{"location":"#troubleshooting","text":"Replication Failures Snapshot Creation Failed Error: Snapshot Creation Failed Impact: Replication fails for all disks of the VM Resolution: Locate the VM in protected infrastructure using the console (AWS Console, GCP Console, vCenter Server) & Delete all snapshots named \u201cDM_REPL_SNAP\u201d. Error while attaching Volume Error: Error while attaching volume Impact: Replication fails for all disks of the VM Resolution: In case the recovery site is AWS or GCP and during protection of VM IOPs are specified, then based on the conditions specified by the cloud provider, the IOPs value may need to be altered. VM not found Error: VM not found Impact: Replication fails for all disks of the VM Resolution: This error happens when a protected virtual machine is renamed. Datamotive detects this change and generates an alert but doesn\u2019t update it\u2019s records unless user takes specific action against that alert. Subsequent replication iterations of the VM keep failing. To resolve this issue. locate the Alert corresponding to given VM and \u201cTake Action\u201d on it. It will open up Edit Protection Plan wizard which should be completed. Once the protection plan is successfully edited, the VM\u2019s replication should start again. Replication failed in GCP Error: Replication failed. *** Quota 'SSD_TOTAL_GB' exceeded. *** Impact: Replication fails for all disks of the VM Resolution: Check your SSD quota configured for the project where the Recovery site is configured. The protected VMs are configured to use either Balanced or SSD type of disks and quota in the project is reached. Either free up the space or change the disk type of protected entities to \u201cStandard\u201d. AWS: Instance |Unable to connect to server Error: Unable to connect to server Impact: Instance replication will not start Resolution: This happens when there is communication problem between the source VM and the Management servers. Please allow the required ports on the management servers and the nodes as mentioned in the deployment Guide. Deployment Guide reference - Deployment Guide Protection Plan Failures Edit Protection Plan Failed Error: VM not found Impact: Protection Plan cannot be edited Resolution: This error can occur when one or more VMs in the protection plan have configuration changes for which user has not taken any action on. To resolve this issue, close the edit protection plan wizard. Go to Alerts section and make sure that you take action on all alerts for VMs within that protection plan. Each action will take ensure the VM\u2019s data is synced with Datamotive. Once all the VMs are updated, then edit protection plan should work as expected. AWS Instance | Failure during the pplan creation Impact : Not able to create pplan Error : Fetch Network details failed:UnauthorizedOperation: You are not authorized to perform this operation.\\n\\tstatus code:403,request id***** Resolution: Please check the permissions for the IAM user as mentioned in the Deployment Guide Deployment Guide reference - Deployment Guide Recovery Failures AWS: Instance not reachable | Check Instance timed out Error: Instance timed out Impact: Instance is not recovered. \u00bd checks pass for AWS Resolution: This error occurs when protected VM doesn\u2019t meet the supported OS criteria. For details, please refer to section Support Matrix in this document. Windows disks are offline Error: After successful recovery of Windows VMs, disks other than the boot disk are found offline Impact: Applications/data if deployed/present on disks other than the boot disks are not accessible. Resolution: This error occurs in case of Windows VMs with multiple disks having disk policy configured as Offline. Edit the disk policy in recovered VMs and configure it to \"OnlineALL\". Reference URL to check the Disk Policy- https://support.purestorage.com/Solutions/Microsoft_Platform_Guide/Multipath-IO_and_Storage_Settings/Disk_Policy_Configuration_-_SAN_Policy","title":"Troubleshooting"},{"location":"#upgrade","text":"The upgrade feature is used to upgrade the Datamotive services, features and the Datamotive UI files. Note - Below steps needs to be done from the Management server only for server as well as nodes. Steps to upgrade the Datamotive Server and the node: Copy the \u201c DM_UPGRADE_ \\<version>.tar.gz \u201d bundle/package to the Management server via Win-scp tool /scp command or any other tool Make sure you give the read permissions to other groups for this uploaded tar bundle Command for changing file permission: Chmod 755 {UPGRADE_PACKAGE_LOCATION} Once the package is uploaded to the server, go to /bin directory using the below command - cd /opt/dmservice/bin We will use the dmcli to upgrade the Datamotive Management server and the node. In /bin directory, enter command the below command \u2013 ./dmcli --help (The above command will show you the available commands in the dmcli option as per the below snip) Command to upgrade the Datamotive Server and nodes \u2013 ./dmcli upgrade --username Administrator --path \\<path of the upgrade package> Command details \u2013 --upgrade: this parameter is used to upgrade the services/features and the UI files --username : Username to login to management server. By default its Administrator --path : Path is absolute path where you have uploaded .tar.gz ( DM_UPGRADE_\\<version>.tar.gz ) bundle on current management server Eg. If the Datamotive Upgrade file ( DM_UPGRADE_\\<version>.tar.gz ) is uploaded to /home/centos location, then the command would be \u2013 ./dmcli upgrade \u2013path /home/centos/DM_UPGRADE_1-0.tar.gz \u2013username Administrator After the successful upgrade of the server and the node, success message would be displayed as per the below snip-","title":"Upgrade"}]}