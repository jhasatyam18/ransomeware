{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Datamotive Hybrid Multi-Cloud Workload Mobility and Business Continuity product suite delivers a disaster recovery and workload migration service and offers cloud economics to help keep your disaster recovery and migration costs under control. Datamotive Workload Mobility can be used to protect your virtual machines/instances on primary site by replicating them periodically to the recovery site. The protected virtual machines/instances can then be recovered as needed in the recovery site as native instances (E.g., protected virtual machine is recovered as a native AWS EC2 instance or a GCP Compute instance). Current release of product has been tested on VMware, AWS and Azure as Protected Site and VMware, AWS, GCP and Azure Cloud as Recovery Site. This document provides information about how to install and configure Datamotive solution. It also provides a general overview of Datamotive solution and it\u2019s different components. Intended Audience This information is intended for anyone who wants to use Datamotive solution. The information is written for experienced Windows or Linux system administrators who are familiar with virtual machine technology and datacenter operations. Supported Datamotive Solution Version The contents of this guide are applicable to Datamotive solution EasyMigrate & EasyHybridDR version 1.x Datamotive Component Architecture Datamotive solution is composed of following components deployed as independent virtual machines . All the components are shipped either as virtual appliances or cloud native machine images depending on the target infrastructure Datamotive Management Server \u2013 a virtual appliance deployed in protected or recovery site infrastructure where the virtual machines need to be protected or recovered or migrated. Management Server provides user interface (UI), a CLI and RESTfull APIs for the IT administrators to perform Day0-DayN activities. The server also acts as replication node. It is shipped as an OVA for VMware environment & cloud native machine image for AWS, GCP & Azure environments. Management server supports parallel replication & recovery for smaller loads (Upto 20 Virtual Machines disks) Datamotive Replication Node \u2013 a virtual appliance deployed in protected or recovery site . It is used to execute the data replication jobs. This node can be used to increase the overall replication capacity of the solution based on the number of protected VMs/instances. Maximum number of parallel replication jobs (1 replication job per protected disk/volume) supported by each node is defined by the limit provided by Cloud platforms (AWS: 20, GCP: 128) . However, for optimum performance, Datamotive solution limits the capacity of each replication node to 20 parallel disks. It is shipped as an OVA for VMware environment & cloud native machine image for AWS, GCP & Azure environment. Datamotive solution scales horizontally using the Replication Nodes Datamotive Prep Node \u2013 a Windows virtual appliance deployed in the recovery site infrastructure (VMware, AWS, GCP or Azure). This appliance is powered-on and used only when Windows VMs are getting recovered or migrated. It is shipped as an OVA for VMware environment & cloud native machine image for AWS or GCP environment. Each Prep Node supports parallel replication & recovery for smaller loads (Upto 20 Virtual Machines disks). Datamotive solution scales horizontally using the Prep Nodes Datamotive DeDup Node \u2013 a virtual appliance deployed in the recovery site (public cloud) infrastructure (AWS, GCP and Azure). It maintains the checksum & data for data chunks transferred to this site. DeDup node provides an interface to check and provide data chunks whenever queried. It is shipped as native cloud image for AWS, GCP and Azure environments. Following diagram shows the deployment & network topology of these nodes What can you do with Datamotive Datamotive currently provides fully functional and intuitive GUI, APIs & Python SDK for performing all supported operations. Once deployed, admins can access the Datamotive GUI by logging in to the Management Server on Protected Site. The URL for accessing the management server is Server IP Address>:5000. Default credentials to access the application are administrator/admin . DR Administrators can perform following set of Day1-DayN operations using the Datamotive GUI. Subsequent sections of this document describe the user interface and related options in detail. Category Action/Activity Description Quick Link Provisioning Nodes Management Management of different nodes of Datamotive solution Nodes Configuration Site Management Creation and management of protected & recovery sites using the nodes already created Sites configuration Protection & Recovery Protection Plan Create & manage protection plans for workload protection Protection Plans Test Recovery Validate replicated instances through non-disruptive test recovery Test Recovery Full Recovery Recover protected instances on recovery site Full Recovery Migration Migrate instances from source to target platform Migration Reverse Reverse/Re-protect VMs to original source Reverse Monitoring Replication/Recovery Jobs View replication & recovery jobs for their replication statuses Jobs Events/Alerts View, Acknowledge, Take Action on Events & Alerts Monitor Infrastructure Monitor & Detect changes in protected instances and take appropriate corrective actions on recovery instance configuration Configuration User Management View users of system with their roles & privileges Users Bandwidth Throttling Configure bandwidth usage for changed data transfer Throttling Email Settings Configure email settings to enable email notifications for supported alerts Email Tech Support Manage support bundle creation for troubleshooting purposes Tech Support Scripts User defined custom scripts to be executed during recovery operations Scripts License Manage licenses License Support Matrix Infrastructure Component Support Source Platforms VMware, AWS & Azure Target Platforms VMware, AWS , Azure & GCP Workloads Virtual Machines with directly attached block storage VMware First Class Disks Component Supported Versions VMware vCenter Server vCenter Server 6.5 (U3) vCenter Server 6.7 vCenter Server 6.7 (U1, U2, U3) vCenter Server 7.0 ESXi Host ESXi 6.5 (GA, U1, U2) ESXi 6.5 (U3) ESXi 6.7 (GA, U1, U2) AWS EC2 GCP Machines Azure Virtual Machines Guest OSs Component Supported Versions CentOS 7.9 Kernel Versions: 3.10.0-1160.80.1.el7.x86_64 3.10.0-1160.76.1.el7.x86_64 3.10.0-1160.71.1.el7.x86_64 3.10.0-1160.66.1.el7.x86_64 3.10.0-1160.62.1.el7.x86_64 3.10.0-1160.59.1.el7.x86_64 3.10.0-1160.53.1.el7.x86_64 3.10.0-1160.el7.x86_64 7.8 Kernel Versions: 3.10.0-1127.19.1.el7.x86_64 3.10.0-1127.18.2.el7.x86_64 3.10.0-1127.13.1.el7.x86_64 3.10.0-1127.el7.x86_64 8 stream 4.18.0-408.el8.x86_64 (ext4 filesystem) 8.2 Kernel Versions: 4.18.0-193.el8.x86_64 4.18.0-193.28.1.el8_2.x86_64 8.5 Kernel Versions: 4.18.0-348.el8.x86_64 4.18.0-348.23.1.el8_5.x86_64 8.6 Kernel Versions: 4.18.0-372.26.1.el8_6.x86_64 RHEL 7.9 Kernel Versions: 3.10.0-1160.80.1.el7.x86_64 3.10.0-1160.76.1.el7.x86_64 3.10.0-1160.71.1.el7.x86_64 3.10.0-1160.66.1.el7.x86_64 3.10.0-1160.62.1.el7.x86_64 3.10.0-1160.59.1.el7.x86_64 3.10.0-1160.53.1.el7.x86_64 3.10.0-1160.el7.x86_64 7.8 Kernel Versions: 3.10.0-1127.19.1.el7.x86_64 3.10.0-1127.18.2.el7.x86_64 3.10.0-1127.13.1.el7.x86_64 3.10.0-1127.el7.x86_64 8.2 Kernel Versions: 4.18.0-193.el8.x86_64 4.18.0-193.28.1.el8_2.x86_64 8.5 Kernel Versions: 4.18.0-348.el8.x86_64 4.18.0-348.23.1.el8_5.x86_64 8.6 Kernel Versions: 4.18.0-372.26.1.el8_6.x86_64 Ubuntu Ubuntu 14: 4.4.0-148-generic Ubuntu 16: 4.15.0-45-generic 4.15.0-142-generic 4.10.0-28-generic Ubuntu 18 5.4.0-42-generic, 5.4.0-72-generic 5.4.0-91-generic Ubuntu 20: 5.11.0-27-generic Oracle Linux Oracle 7.8 4.14.35-1902.300.11.el7uek.x86_64 4.14.35-2047.519.2.1.el7uek.x86_64 Oracle 7.9 5.4.17-2102.201.3.el7uek.x86_64 5.4.17-2136.313.6.el7uek.x86_64 Windows Standard & Datacenter editions of following versions. 2K12 R2 2K16 2K19 SUSE Suse 15 SP3 Kernel version: 5.3.18.57-default Suse 15 SP2 Kernel version: 5.3.18.22-default Client Browsers Component Supported Versions Google Chrome 99.0.4844.82 99.0.4844.84 107.0.1418.56 107.0.5304.122 Microsoft Edge 100.0.1185.29 107.0.1418.56 Mozilla Firefox 98.0.2 Features Authentication Open the Datamotive UI through URL: \\< Datamotive_Service_IP >:5000 Provide the username and password and press Login On successful login, User will see the Datamotive Dashboard. By default Datamotive will create following three users Administrator DRadmin Guest Default password for all the users is \u2018admin\u2019 Note: If you are login first time then for security reasons password change is must. Provide the current password and new password. Click on change password button to set new password for the system. Dashboard The Dashboard provides you with an at-a-glance overview of the data protection status of your environment. The Dashboard contains the following features. Title Windows Title windows will give overall status on your configured and protected environment. Title Description Sites Sites configured on the node. Protection Plans Protection plans configured. Protected Machines Total number of protected virtual machines Storage Overall protected storage size. Alert Statistics Active/Unacknowledged alerts which need a user action acknowledgement or action. RPO and RTO Statistics Current recovery time objective and recovery point objective. Title Description RPO Average recovery point objective value RTO Average of recovery time object value Test Executions Test executions completed successfully. Full Recovery Virtual machines recovered successfully. Migrations Virtual machines migrated successfully. Replication Statistics Replication statistics provides an overview of your protected environment replication jobs. Label Description Completed Successfully completed replication iterations. Running Replication iterations which are in-progress. Failed Failed replication iterations. Change Rate Average data change rate for all protected virtual machines Data Reduction Average percentage of data reduction for all the completed replications. Jobs Jobs shows the recently started or completed task in the system. Virtual Machine Protection Analysis Virtual machine protection analysis shows the overall status of recovery site environment in terms of total discovered virtual machines with percentage of protected and unprotected virtual machines. In addition to protection analysis, this wizard also provides the details for replication statistics of virtual machines which are in-sync and not in-sync. Bandwidth Usage Bandwidth usage provide the details network usage of the system for last 12 hours. The bandwidth usage chart shows data downloaded and uploaded for last 12 hours. Site Connections Provides connection details of configured sites in terms of data flow i.e., from which source site data replication is configured for target site. Events Events are records of user actions or system actions that occurred in the Datamotive system. The Events widget provides most recent 5 events generated in the system. Nodes This section displays all the nodes registered with the management node along with their status. This is a snapshot for how different nodes in Datamotive are working together. Nodes Configuration Nodes are entities where the Datamotive server is installed (Ex. AWS, GCP, VMWare, Azure, etc.). Datamotive Nodes are of different types like Management, Replication, Dedup & Win Prep. Each node has specific functionality. Management: Node for performing Datamotive management operations. There must be one and only Management node for each site (vCenter Server for VMware & a Region/Zone in Cloud). Management also has a replication engine which allows it to double up as replication node too. Replication: Nodes responsible for performing replication activities. These can be added based on number of Virtual Machine disks to be replicated in parallel. Any number of nodes can be added to meet the requirement for large scale environment. Dedup: This is a special type of node required to support deduplication. This node is required only on the Recovery site. Win Prep: This is also a special type of node required only on Recovery site to perform Windows workloads recovery. For all the nodes, Datamotive provides separate OVAs & cloud specific machine images. Once Node of given type is deployed in the infrastructure, it needs to be added in the Datamotive Management server. Nodes must be deployed and configured in following manner. Management Node: Deploy 1 management node per protected site. Local node representing the management node automatically gets registered. Remote Management Node: Deploy 1 management node per recovery site. Register the management nodes from Recovery Sites in Management Node of Protected Site. Replication Nodes: Deploy replication node based on load. Once deployed register replication node in the local management server. Replication nodes are always added to local management node only. Currently, Datamotive supports replication of 20 virtual disks per replication node. Dedup Node: Deploy the Dedup node on Recovery Site. Once deployed, register the Dedup node with Management Node on the Recovery Site. Win Prep Node: Deploy the Win Prep node on Recovery Site. Once deployed, register the Win Prep node with Management Node on the Recovery Site. To Access Node option, Go to Configure -> Nodes (Note- By default the Local node will be configured.) To add new node - Click On \u201c+ New \u201d option as shown below - It consists of the below options- Name Name to identify the node. For management node, the name must be \u201cdm-repl-server\u201d. For all other nodes, the name has to be same as that of name of the VM where this node is deployed. Hostname This is FQDN or IP address of the server Username This is the username of the Datamotive Engine Password This is the password of the Datamotive Engine Type The type of Datamotive server which is being added. Type consists of 4 options - Management, Replication, Prep Node and Dedupe Server In Type select the appropriate option from the drop down - Type Description Management Core management server Replication Used for replicating the changed data from source to target & during recovery operations Prep Node Prep Node is used when you would want to recover the Windows server Dedupe Server Used for de-duplication of data (Note \u2013 Based on the selection of Type, further details need to be entered). Ex. In option, the management type is selected. It consists of the below options - Platform Type Platform where the node is deployed Management port Port on which the management service runs (By default, it 5000) Replication Data Port Port on which the replication data service runs (By default, it 5001) Replication Controller Port Port on which the replication controller service runs (By default, it 5003) Encryption Key Data will be encrypted using this key while transferring from one node to another node. The key for the node can be accessed in the remote management node, under the node configuration section. Once the details are entered click on Configure option. Sites configuration Sites are infrastructure where the source or target workloads reside. Site consists of platform type and platform details. In the Datamotive UI, go to Configure tab on the left-hand side panel and select Sites. Site can be of following types: Protection - A protection site is the source of the protection plan workload replication. Recover - A Recover site is the destination for the protection plan workload replication. Create Site To create site, click the \u201c+ New\u201d button and Create site windows will pop-up. The common inputs are Name Desired name to identify the site Description Short information about the site Site Type (Protect/Recover) - Select the site type based on source or destination. Platform Type Select the Platform type - VMware/AWS/GCP/Azure Node Select the node based on the Platform type where the workloads are hosted (Note: Based on the platform type and node the options change) Platform Specific Parameters: Platform Type Parameter Description VMware vCenter Server IP Enter the vCenter Server IP address where the workloads are hosted Port Enter the Port on which vCenter Server is running. Default is 443 Username Enter the vCenter Server username Password Enter the vCenter Serer password AWS Region Select the desired region where the workloads will be Protected/Replicated/Recovered Zone Select the desired zone in the region where the workloads will be replicated/recovered Access Key AWS User Access Key Secret Key AWS User Secret Key GCP Region Select the desired region where the workloads will be replicated/recovered Zone Select the desired zone in the region where the workloads will be replicated/recovered Project ID Enter the project id from the GCP console Azure Region Select the desired region where the workloads will be replicated/recovered Subscription ID Enter the Azure subscription ID Storage Account Enter the Azure storage account used for target VM storage Tenant ID Enter the Azure AD App Tenant ID Client ID Enter the Azure AD App Client ID Secret Key Enter the Azure AD App client secret key Click on configure to create the site and on successful creation, site will be listed in the list view. V Center Server IP Edit Site To Edit a site, click on Edit button and then Edit windows will pop-up. Edit the input which need to be changed and click on configure to save the configuration. Remove Site Click on Remove button to delete one or more sites. On click of confirm, the sites will be deleted. Make sure that site isn\u2019t referred in any Protection Plan before removing. Protection Plans Protection Plans are the core units for protecting the workloads. Protection Plans define source & target sites, virtual machines to be protected, their boot orders, replication schedule, recovery configuration for the virtual machines. All of these steps are configured using a wizard. Based on this information, Datamotive performs the replication & recovery operations. Create Protection Plan To create a new protection plan, click on + New button in protection plan list, create protection plan wizard is shown. Follow the guided steps to configure protection plan. Prerequisite VMware platform: VMware tools must be installed in all the Virtual Machines which needs to be protected. CBT (Change block tracking) must be enabled for all the Virtual Machines and their disks. Step 1: General Name Desired name of the protection plan Protect Site Source protection site Recovery Site Destination recovery site Step 2: Virtual Machines Select the virtual machines to be protected and click next. Use search & pagination to find virtual machines. Step 3: Recovery Configuration Provide the virtual machine specific recovery configuration which will be used for creation of instance on recovery site. Recovery configurations vary based on Recovery Site Type. Below are the options user need to configure for each protected instance. General For target cloud platforms, following information is required to be provide by user. All the values are fetched live from the target platform and only the ones available and supported are provided as an option. Instance Type Instance type on cloud site - Example t2.micro on AWS or n1-standard-1 on GCP Volume Type Instance volume type on cloud site - Example GP-2 on AWS or standard on GCP. Volume IOPs IOPs value for supported Volume Types. Please note that the IOPs values are submitted for volume creation without validations. Make sure that all the rules specific to selected volume type are followed while specifying the IOPs value Tags Instance tags. Example \u2013 Tag Key \u2013 Name Tag value \u2013 dm-repl-node For VMware as target platform, the user has to provide selection for following fields Location Folder in target vCenter server where the VM needs to be placed Compute ESXi Host (standalone) or ESXi Host Cluster where the VM needs to be deployed Storage Datastore (standalone) or Datastore Cluster where the VM\u2019s all the disks will be placed CPU Number of vCPUs to configure for the VM Memory Amount of memory to be configured for the VM For Azure as target platform, the user has to provide selection for following fields Resource Group Resource group in target Azure subscription Availability Zone Availability zone in which the VM will be deployed VM Size Virtual Machine size on Azure cloud \u2013 Example Standard_B2s Volume Type Virtual Machine volume type on Azure cloud \u2013 Example Premium SSD Tags Virtual Machine tags. Example \u2013 Tag Key \u2013 Name Tag value Network For instance, network configuration click on config button, will open a network configuration popup window. Network configurations vary based on the target platform For AWS platform as recovery site, the following configuration options are provided- VPC Virtual Private Cloud (Amazon VPC) enables you to launch AWS resources into a virtual network that you've defined. Create from Source This option is used when you need to copy the network configuration from the source instance. All the options like subnets, IP address and security groups get auto-filled as the source instance. This option is supported only in case of AWS to AWS Subnet Subnet ID which will assigned to the instances in this protection plan. For AWS to AWS, subnets from all zones within target region are displayed. From any other source to AWS, subnets from zone where the Datamotive node is deployed are displayed. Datamotive supports multi-zone recovery only when both source and target is AWS. Auto Public IP Click on the checkbox if you want to auto assign a public Ip to instance. Note - only one network card can be configured if public Ip is enabled. Elastic IP Select from allocated elastic IP address pool if any. Private IP Provide the internal IP address for the instance or leave blank for auto assignment. (Please ensure to specify Private IP in the same range as that of given Subnet and is unique too) Security Groups Select the security groups all configure inbound and outbound traffic for the instance. For GCP platform provided the following details Network Network which will be assigned to the recovered instances in the Protection Plan Subnet Subnet ID which will assigned to the instances in this protection plan Private IP Provide the internal IP address for the instance or leave blank for auto assignment. External IP Select one of the following options if external Ip address is required for the selected network card else select none. 1. Auto: GCP will assign a Ip address from its public Ip pool. 2. None: select if external not required. 3. Reserved IP address, GCP project reserved Ip address, will be listed along with above two options. You can select any reserved Ip address from the list. Network Tier Network Service Tiers lets you optimize connectivity between systems on the internet and your Google Cloud instances. Premium Tier delivers traffic on Google's premium backbone, while Standard Tier uses regular ISP network. Firewall Tags The target tag defines the Google Cloud VMs to which the rule applies For VMware platform provided the following details Network Network which will be assigned to the recovered instances in the Protection Plan Adapter Type Adapter type to be configured to the Virtual Machine. This is a complete list of vSphere supported adapter types. User has to carefully select the appropriate adapter which is available in his setup Mac Address Assign a specific Mac Address to a NIC of the VM. When left empty, default Mac Address is assigned by vCenter Server Configure Guest Network Select this option if you want configure static IP address to a NIC of the VM. When selected static IP configuration fields show up IP Address IPV4 address to be assigned to the VM Subnet Mask Subnet mask as applicable from the network Default Gateway Default gateway to be used for communication DNS Server One or more DNS servers specified in a comma separated list For Azure platform as recovery site, the following configuration options are provided- Virtual Network Virtual Network enables you to launch Azure VM into a virtual network that you've defined. Subnet Subnet ID which will assigned to the VM in this protection plan. Private IP Provide the internal IP address for the VM or leave blank for auto assignment. (Please ensure to specify Private IP in the same range as that of given Subnet and is unique too) Public IP Select any public IP from the pool or select auto for automatic assignment Security Groups Select the security groups all configure inbound and outbound traffic for the VM. Step 4: Replication Scripts Datamotive supports executing custom scripts at various levels to allow all the customizations users need for replication & recovery workflows. The scripts are supported for individual VM and complete protection plan as well. The scripts are available as both, pre and post hooks. To use pre or post scripts, first upload the pre & post scripts to Datamotive management node on both protected & recovery sites using scripts section in settings. Once the scripts are uploaded, they will be visible in the pre and post replication scripts option. Datamotive currently supports Python 3.x, Golang & Shell executable scripts. All the scripts must be in form of executables to work. E.g. they should get executed as ./\\<script_file_name>. Scripts are supported at following different levels. The scripts are also executed in the below order during replication & recovery operations. Script Type Execution Level Script Description Replication Protection Plan Pre-Script Executed in each replication iteration as a first step. Virtual Machine Pre-Script Executed in each replication iteration before every virtual machine\u2019s snapshot is taken Virtual Machine Post-Script Executed in each replication iteration after virtual machine\u2019s snapshot is completed Protection Plan Post-Script Executed in each replication iteration after all the virtual machine\u2019s snapshot operation is completed Recovery Protection Plan Pre-Script Executed during Test/Full Recovery & Migration operations as a first step Virtual Machine Pre-Script Executed before starting recovery of every virtual machine Virtual Machine Post-Script Executed after every virtual machine is recovered Protection Plan Post-Script Executed after completion of recovery operation for all virtual machines. Following screens show options where user can select/upload various scripts. Scripts Input Currently, Datamotive supports only binary for execution. The runtime available for scripts is Shell, Bash, Python 2.x & GOLang. In future, binding for different languages will be provided. On invocation the recovery scripts, Datamotive provides following parameters in the order. Pre-script: \\<None> Post-script: JSON string with following format { [ { \u201cName\u201d: \\<VM Name>, \u201cSourceID\u201d: \\<Platform ID of source VM>, \u201cTargetID\u201d:\\<Platform ID of recovered VM>, \u201cNetworkInfo\u201d: [{ \u201cPublicIP\u201d: \\<Public IP if assigned to recovered VM>, \u201cPrivateIP\u201d: \\<Private IP if assigned to recovered VM> }], \u201cCredentials\u201d: { \u201cUsername\u201d: \\<Login username of the recovered VM>, \u201cPassword\u201d: \\<Login password of the recovered VM> } } ] } Scripts Output The scripts are checked for it\u2019s completion and the process exit status is captured. If there are no errors in executing the script, Datamotive considers it to be successfully executed. If there are errors, the recovery is marked as Partially Completed. Step 5: Boot Order Using boot order configuration defines the boot delay and virtual machine boot order. Boot Delay : Delay in seconds between virtual machines specified in the boot order Boot Order : Order in which virtual machines will get recovered or migrated. Lower number will get recovered first Step 6: Replication Configuration Replication configuration allows user to specify the schedule for periodic replication of protected virtual machines. User can configure following parameters. Start Time Time from when protection plan replication will start. Replication Interval Time interval in which the virtual machine\u2019s changed data will be replicated Encryption on Wire Data encryption while transferring from source to destination. Compression Data compression while transferring from source to destination Dedup Enables the data deduplication. Note: Deduplication node should be pre-configured on recovery site before using this feature Differential Reverse Replication Enable this feature if you want to allow recovered machines from the recovery site to replicate back to its original source site. Step 7: Scripts As described in earlier scripts section, these are Replication & Recovery scripts at Protection Plan level. The runtime available for scripts is Shell, Bash, Python 2.x & GOLang. In future, binding for different languages will be provided. On invocation the recovery scripts, Datamotive provides following parameters in the order. Pre-script: \\<None> Post-script: Post script gets 3 ordered parameters Recovered VM information: JSON string with following format {\"vms\":[ { \"name\":\\<VM Name>, \"sourceID\":\\<Platform ID of source VM>, \"targetID\":\\<Platform ID of target VM>, \"ips\":[ {\"publicIP\":\\<Public IP if assigned>, \"privateIP\":\\<Private IP is assigned>} ], \"credentials\":{ \"username\":\"\\<Recovered VM logon username>\", \"password\":\\<Recovered VM logon password> } } ] } User Inputs: As provided by user. Output of Recovery Pre-Script: JSON string with following format {\"status\":\"\",\"code\":0,\"message\":\"\",\"data\":\"\"} Step 8: Summary Review the summary for the protection plan and click finish to configure the protection plan. On successful configuration, replication jobs will start for the virtual machines selected for this protection plan. Protection Plan Actions Action on protection plan is available through the protection plan list and through the protection plan details page. Action will get enable depending upon the context and state of the protection plan. Protection Plan actions also differ based on whether the plan is viewed on protected site or recovery site. Certain actions are available only at one site as shown below Actions available through the protection plan details Actions for source site Actions for recovery site Actions available through the protection plan data grid view on source site New: Click to configure new protection plan. Edit: Select protection plan from the list and click edit. Edit protection plan wizard will get open. In edit protection following operations were allowed Add new virtual machine to plan. Remove protected virtual machine from the plan. This action gets completed on next successful iteration of the protection plan. The VM shows as \u201cRemoving\u201d till that time. Recovery configuration modification. Boot order configuration & modification. Replication configuration Scripts modification. Start : Start Replication for the selected protection plan. Stop: Stop the protection plan replication. Remove: To remove the protection plan, click on the Remove button and it will ask for the confirmation. On confirm, the protection plan will get deleted. Note protection plan should be in stopped state with no running jobs. Recovery After the Protection Plans are configured and replication of virtual machines is in-sync, user can trigger various recovery operations from the Datamotive Management Server on the recovery site. To initiate recovery or migration go to Configuration \u2014> Protection Plan -> Click on the protection plan on which recovery or migration operation need to perform. Click on the Actions button. All available operation will get listed. Test Recovery Prerequisite At least one replication job has been completed successfully for the virtual machine and the sync status for that job should be In-sync. Step 1: Select Virtual Machines Select the virtual machines for the test recovery. Provide the credentials to execute the pre and post scripts. If there are no scripts for the virtual machine, then credentials are not mandatory. Credentials are not stored anywhere and only been used for the workflow. NOTE: For Windows recovery on AWS, Credentials are mandatory even if there are no scripts. Step 2: Test Recovery Configuration Configure test recovery instance for it\u2019s compute, storage & network to ensure a non-intrusive test recovery drill. Step 3: Tools & Scripts Install System Agents: For AWS, install OS agents like EC2Launch and SSMAgents. For GCP, install google os-config and compute-engine agents. For Azure, install Azure VM agent Install Cloud Packages : For AWS. install AWS Cloud SDK and for GCP, install GCP Cloud SDK. For VMware only Install System Agents is available as there no cloud packages Cleanup: Select this flag to clean-up all previously created test recovered instances for selected VMs Run Protection Plan level scripts: Select this option if you want to execute recovery scripts configured at protection plan level. Typically, these scripts perform changes to infrastructure like DNS entry changes etc. which is not desirable in case of test recoveries. If you have configured such scripts and do not wish to execute them in Test Recovery cycles, you can skip this step. Step 3: Summary Review the summary and click on finish to start the test recovery. This will start the test recovery jobs for the selected virtual machines and jobs can be monitored in the Jobs \u2014> Recovery. Test Recovery validation Check the status of the virtual machine's recovery jobs in the Jobs \u2014> Recovery. Check the Cloud Console (AWS, Azure and GCP) for the instances with the virtual machines name and their running status. AWS also has status checks. On successful completion of recovery jobs, IP Address can be found for the new running instances. For Windows machines, download the RDP file by click the download button right next to the IP address and check the windows machine through RDP. For Linux machines, copy the IP address and check the linux machine through ssh. Note: Once the validations are completed, Datamotive recommends to remove the Test Recovered instance. Leaving test recovered instances running may lead to increased cloud cost. Full Recovery To perform full recovery after disaster in the source site, open Management Application on Recovery Site and go to Configuration \u2014> Protection Plan \u2013> Click on the Protection plan. Click on Action button and select Recovery Prerequisite: At least one replication job has been completed successfully for the virtual machine and the sync status for that job should be init-success. Step 1: Select Virtual Machines Select the virtual machines for the recovery. Provide the credentials to execute the pre and postscripts. If there are no scripts for the virtual machine, then credentials are not mandatory. Credentials are not stored anywhere and only been used for the workflow. NOTE: For Windows recovery on AWS, Credentials are mandatory even if there are no scripts. Step 2: Recovery Configuration Install System Agents: For AWS, install OS agents like EC2Launch and SSMAgents. For GCP, install google os-config and compute-engine agents. For Azure, install Azure VM agent. Install Cloud Packages : For AWS. install AWS Cloud SDK and for GCP, install GCP Cloud SDK. Step 3: Recovery Summary Review the summary and click on finish to start the recovery. This will start the recovery jobs for the selected virtual machines and jobs can be monitored in the Jobs \u2014> Recovery. NOTE: If the replication job is on-going at the time of Full Recovery, then the instance will be recovered from the last known good state. Recovery Job Status Migration Migration also follows the recovery workflow for the protected VMs. To migrate the workloads, go to Configuration \u2014> Protection Plan \u00e0 Click on the protection on which migration need to perform, on the Recovery site. Click on actions buttons and select Migrate Prerequisite: In case of migration, to make sure there is no loss of data, the virtual machine(s) should be in power off state and the last replication jobs should be successfully completed with zero changed data. Step1: Select Virtual Machines Select the virtual machines and provide the credentials if there are pre- or post-configured for these virtual machines. Note: For Windows machine in AWS, credentials are mandatory. Step 2: Recovery Configuration Install System Agents: For AWS, install OS agents like EC2Launch and SSMAgents. For GCP, install google os-config and compute-engine agents. For Azure, install Azure VM agent. Install Cloud Packages : For AWS. install AWS Cloud SDK and for GCP, install GCP Cloud SDK. Step 3: Summary Review the summary and click on finish to start the Migration . This will start the test migration jobs for the selected virtual machines and jobs can be monitored in the Jobs \u2014> Recovery jobs. Job's view after migration completed Reverse The Reverse protection plan or Re-protect option is available when the Virtual Machines needs to be replicated back to the original Source Site (Especially in case for Disaster Recovery) Currently reverse is supported from AWS/VMware/Azure to AWS/VMware/Azure. Reverse option is available at protection plan level under the Actions option. The option is enabled only after the protection plan is fully recovered. After the reverse option is clicked, the pop-up for the reverse workflow opens - Replication Type: The option allows you to configure the Replication Type. Following replication options are available to be configured. Full Incremental \u2013 With this option entire workload data is replicated back to the original source site in the 1st iteration and then onwards the incremental data (changed data) is replicated. This option has to be used when In the original plan, \u201cEnable Reverse Differential\u201d option was not selected Even after \u201cEnable Reverse Differential\u201d option was selected, the original site does not have same state from which the workloads were recovered. Same state is defined when the state of infrastructure (Hosts, Datastores, VMs, their snapshots) etc. is exactly the same as what it was before the disaster. Differential- With this option only the differential data which is changed on current source is transferred back to original source. This option ensures that complete workload is not transferred back and hence the replication process is fast. This option can be used only when the \u201cEnable Reverse Differential\u201d option was selected in the original plan before the Full Recovery Recovery Machines Suffix: Configure desired suffix which will be assigned to the recovery entities created on the original source site. This helps differentiate the replicated workloads from the original ones while reverse protecting them. Replication Interval: Configure desired replication interval for reverse protection As a next step, the Recovery Configuration wizard would appear \u2013 The step allows to configure recovery entity properties supported by the target platform. For example, the screenshot shows details for VMware platform where user can select Location \u2013 Desired location/folder where the recovered VM would reside Compute \u2013 The Host IP address Storage \u2013 The datastore in the host CPU \u2013 Number of CPU assigned to the recovered VM Memory - Memory assigned to the recovered VM In Network, the networks assigned to that particular VM will be visible and the when the config option is clicked the network and Subnet/Network Adapter The next step allows to reconfigure the scripts, so that all the automation can be done in target platform. The scripts function in the same way as that of forward recovery. Below table illustrates different types of scripts supported by Datamotive platform. Script Type Execution Level Script Description Replication Protection Plan Pre-Script Executed in each replication iteration as a first step. Virtual Machine Pre-Script Executed in each replication iteration before every virtual machine\u2019s snapshot is taken Virtual Machine Post-Script Executed in each replication iteration after virtual machine\u2019s snapshot is completed Protection Plan Post-Script Executed in each replication iteration after all the virtual machine\u2019s snapshot operation is completed Recovery Protection Plan Pre-Script Executed during Test/Full Recovery & Migration operations as a first step Virtual Machine Pre-Script Executed before starting recovery of every virtual machine Virtual Machine Post-Script Executed after every virtual machine is recovered Protection Plan Post-Script Executed after completion of recovery operation for all virtual machines. Once the Next option is clicked, the below wizard for configuring the boot order appears \u2013 Using boot order configuration defines the boot delay and virtual machine boot order. Boot Delay : Delay in seconds between virtual machines specified in the boot order Boot Order : Order in which virtual machines will get recovered or migrated. Lower number will get recovered first On clicking Next button, options to set replication configuration is available- Replication configuration allows user to specify the schedule for periodic replication of protected virtual machines. User can configure following parameters. Start Time Time from when protection plan replication will start. Replication Interval Time interval in which the virtual machine\u2019s changed data will be replicated Encryption on Wire Data encryption while transferring from source to destination. Compression Data compression while transferring from source to destination Dedup Enables the data deduplication. Note: Deduplication node should be pre-configured on recovery site before using this feature Differential Reverse Replication Enable this feature if you want to allow recovered machines from the recovery site to replicate back to its original source site. Clicking the Next button presents the options to set protection plan level scripts. As described earlier in the protection plan creation section, these are Replication & Recovery scripts at Protection Plan level. Next is the Summary which is the last step in the wizard to review the reverse configuration and click finish to reverse the protection plan. On successful reversal, replication jobs will start for the virtual machines in the protection plan and can be viewed in the jobs sections Jobs Jobs are logs of every replication & recovery action performed in the system. Datamotive maintains detailed information of each job executed by the system. Jobs provide a real time mechanism to view the currently executing operations in the system. Navigation: Jobs You can use the Jobs page to monitor the overall status of replication and recovery jobs. Replication The Replication Jobs tab provides details about all the running, completed, and failed replication iterations. The Replication job section has the following sub-section to show replication jobs base on the grouping criteria. Protection Plan Navigation: Jobs --> Select Protection Plan. Protection plan replication details provide a list of protection plans. Each protection plan has its associated virtual machine replication information. click icon or title to view protection plan level details. Column Name Description Name Name of virtual machine associated with the protection plan. Iteration The total number of replication iterations completed. Total Changed Total data changed. Total Transferred Total data transferred to the replication server. Data Reduction (%) Overall data reduction. Job Status Status of latest replication iteration. Completed : Replication was completed successfully. Started : Replication is running. Partially Completed : Replication completed with errors. Failed : Replication failed. Sync Status Virtual machine sync status. Init-success : The first iteration completed successfully. Init-in-progress : The first iteration is running. Init-failed : The first iteration failed. In-sync : Iteration is completed within configured replication interval time. Exceeded interval : Iteration is completed but took more time than configured replication interval time. Sync-failed : Replication iteration failed. Virtual Machines Provides a list of replication details for each protected virtual machine. Note: For failed jobs, hover on the Sync Status column to get details of the status. Hover on the Replication Duration column to get Replication start & end time. Column Name Description Virtual Machine Name of the protected virtual machine. Iteration Total number of replication iterations completed. Changed Total changed data discovered. Transferred Total data transferred to the replication server. Replication Duration Time took to complete iteration. Job Status Status of replication iteration. Sync Status Virtual machine sync status. Disks Provide a list of replication details for each protected virtual machine disk/volume. Column Name Description Virtual Machine Name of the protected virtual machine. Disk Id Disk id of virtual machine. Data Changed Total changed data discovered for the disk. Data Transferred Total data transferred to the replication server. Replication Duration Time took to complete iteration. Job Status Status of replication iteration. Recovery Jobs The Recovery jobs tab provides details about all the running, completed and failed recovery operations. Protection Plan Protection plan recovery details provide a list of protection plans. Each protection plan has its associated recovered (Full / Test) or migrated virtual machine information. click icon or title to view protection plan level details. Column Name Description Name Name of virtual machine associated with the protection plan. Duration The time required to complete the recovery. Recovery Type Recovery Type (Full Recovery, Test Recovery or Migration) Status Recovery/Migration status. Virtual Machines Provides a list of recovered (Test/Full) or migrated virtual machines. Column Name Description Virtual Machine Name of virtual machine. Duration The time required to complete the recovery/migration. Recovery Type Recovery Type (Full Recovery, Test Recovery or Migration) Job Status Recovery job status. Completed : Recovery completed successfully. Started : Recovery job is running. Partially Completed : Recovery completed with errors. Failed : Recovery failed. IP Address Recovered virtual machine IP address. Monitor Monitor Option is used to see the events, alerts and customized reports as they are generated. Events & Alerts contain audit log information about all the critical actions performed in the system. In Monitor, there are 3 options- Events Alerts Reports Events Navigation \u2013 Monitor -> Events Events are Datamotive server or user generated incidents which are generated automatically when they occur. There are 4 types of Events Information This are events occurred just for the information Warning This are events occurred to take precautionary action Error This are events occurred when there is an issue and needs to be addressed Critical This are events occurred when there is an issue and that needs to be addressed at the earliest To see \u201cEvents\u201d, go to \u201cMonitor\u201d option and click on \u201cEvents\u201d In events, the following information is displayed \u2013 Date The date and time when the event has occurred Topic The topic of the event Level The level of the event occurred (Ex. Information, warning, Error, Critical) Event type the type of the event occurred Description A short description about the event occurred User User who initiated the event Alerts Navigation \u2013 Monitor -> Alerts Alerts are Datamotive server generated warning messages based on the events and are tagged with the severity level they occur. The severity of the alerts is of 4 types - Information These are events for the information Warning These are events which require taking precautionary measures Error These are events which require user attention to address the issue Critical These are events which require immediate user attention to address the issue In Alerts, the following information is displayed \u2013 Title The headline/short description for the alert generated Severity The condition at which the alerts are generated Created The date and time at which the alerts are generated Last updated The date and time at which the alert was checked by the Datamotive server Status The symbol representing the severity of the alert When we click on the Title or Status of a particular alert a window will pop-up with a description regarding that particular alert. It consists of the 2 tabs Info Information about the alert generated Associated Event Event associated with the generated alert The info tab consists of the following \u2013 Severity The condition at which the alerts are generated Event Type The type of event that is associated with the alert Description A short description about the event occurred Created The date and time at which the alerts are generated Updated The date and time at which the alert was checked by the Datamotive server Occurrence The frequency at which the alerts is occurred Acknowledge Message User inputs when the alert is addressed The associated event consists of the following \u2013 Event ID The ID of the event associated with the alerts Level The level of the event occurred (Ex. Information, warning, Error, Critical) Topic The topic of the event Date The date and time when the event has occurred Event Type The type of the event occurred Description A short description about the event occurred Acknowledge Message User inputs when that event is addressed User can perform specific action (system generated) or just acknowledge the alert without taking any action. Certain Alerts, mandate user action to resolve the issue. Once the alert is acknowledged or action is taken by the system, the status of the Alert changes. Reports Navigation \u2013 Monitor -> Report Datamotive provides mechanism to generate Reports listing Nodes, Events, Alerts or Jobs in the system. To generate reports, go to \u201cMonitor\u201d Tab and click on \u201cReports\u201d option- To generate a Report, click on \u201cFilter\u201d option. Click on the components which you want to include in the report. For Protection plan dropdown select if you want to include all protection plan details in the report. Or select a specific plan whose report is required. Once the options are selected, click on \u201cGenerate Report\u201d for the report to be generated. Click on export button to export data to .pdf or .xlsx format. Settings To configure your environment, you can use settings section. Settings section will allow you to configure email, Bandwidth throttling, license and tech support. License Location: Settings \u2014> License License is required to perform the recovery and migrations operations. By default, system will provide a trial license which has a fixed number of migrations and recoveries allowed. Once you perform any migration or recovery operation the respective consumption will reflect in its associated consumption bar. License installation For new license installation, contact the support@datamotive.io with following information. Node Key: You can get node key through the about section of the application. Along with node key provide the details requested by the support team. On successful credential validation Datamotive team will provide you a license file. Once you receive the license form the Datamotive team, navigate to the settings -> license Click on +New button to install the received license. A new modal window will popup. Click on the upload icon to select the license file. Post successful validation the detail of the license is shown. If all the license details look good, then click install. New license will get install in the system. If multiple license available in the system, click on the action button to active or deactivate the license. Scripts Location: Settings \u2014>Scripts Datamotive supports executing custom scripts on recovery of individual virtual machine and complete protection plan as well. Datamotive supports both, Pre & Post scripts. The scripts are executed on the Datamotive management node. To use scripts in protection plan, they need to be uploaded into Datamotive management server on both protected & recovery site. To configure new script, follow below steps. Click on the +New button, new popup will be shown to configure script. Select the script file for the upload Select Pre or Post script type Following actions are available for a uploaded script. Edit: Click on edit icon to edit script. Remove: Click on remove icon to remove script. Email Location: Settings \u2014> Email Email setting allow you to configure the email and recipients details so that Datamotive can send you the critical alerts details over the email. Configuration. Click on the Configure now to open email configuration window. Provide the required details and click Configure. Email Address Email address used to send the communication alerts. Email Password Email Password for the authentication. Note: System will encrypt these details before saving them in the database. SMTP Host SMTP hostname or SMTP server IP address SMTP Port SMTP port number SSL Certificate Verification Click if your smtp server is secure and SSL certificate is installed on it. Replicate Configuration If multiple sites were already connected to the node from where you are configuring the email and you want same settings should get replicate on all the connected sites, then enable this option. Post email Configuration you can view the configured details along with Email Recipients section get enabled. To add new recipient, click on +New icon Provide email address of the recipient Select the events for which you want to send email to recipients. Click configure to add new recipient in the email list for subscribed events. Using action options, you can reconfigure the recipient's details or can delete them from the list. Roles Location: Settings \u2014>Roles Privileges define rights to perform action on an entity of Datamotive. Whereas the role is a set of privileges. Roles are assigned to the user. By default, Datamotive generate following three roles. administrator: With Super Admin role, user can view and perform all the available operations in the system DRadmin: With DR Admin role, user can perform operations related to protection plan and recovery/migration Guest: Read-only user can view all available views but can\u2019t perform any operation. On Left side grid all roles are listed. Click on the role to load its associated privileges and users. Users Location: Settings \u2014>Users Users lists provide all registered users with their assign roles. Tech Support Location: Settings \u2014>Tech Support Support bundle is useful to triage the any issue occurred in the system. To collect new support bundle, follow below steps. Click on the +Generate button, new popup will be shown to trigger bundle creation. Provide a proper description specifying why new support bundle generation is requested and click Generate Bundle Post system accepts the generate bundle request it will collect all the required info from the node. Note: This operation may take several minutes complete, you can check the status of bundle in the list. (Click Refresh to update the status) Once support bundle generation completed, in the action section you will get a download icon. Use Download icon to download the support bundle Use delete icon to remove the support bundle from the system Throttling Location: Settings \u2014> Throttling Throttling allows you the configure the network usage as per requirement. By default, system will use networks full capacity to download or upload the replication data across the sites. If you want to restrict the bandwidth, use then bandwidth throttling configuration is required. Provide the below details and click configure to apply bandwidth throttling. Enable Limit Enable the option if bandwidth throttling is required. Once enable you can provide the bandwidth usage details by scrolling the usage bar or by entering the values in the usage field. Enable Time Limit If time limit base usage configuration required, then enable the option. Once enable you can provide the bandwidth limits along with its start and end time specification over which time base limits will be applicable. Apply To All Replication Nodes If you want to apply same setting on all the replication nodes, then enable this option. If you want to configure each replication node bandwidth throttling, then click on Icon to configure the node specific usage limits. New popup window will be shown to configure the node specific configuration. Provide the details and click configure. Provided configuration will get applied on the node. Upgrade The upgrade feature is used to upgrade the Datamotive services, features and the Datamotive UI files. To upgrade Datamotive solution, execute below mentioned steps on the Management server only for server as well as nodes. Upgrade needs to be done individually on management nodes of all sites. Please note that Datamotive management nodes with different versions on different sites may result in inconsistent behaviour and may impact replication and recovery operations. Steps to upgrade the Datamotive Server and the node: Copy the \u201cDM_UPGRADE_ \\<version>.tar.gz\u201d bundle/package to the Management server via Win-scp tool /scp command or any other tool Make sure you give the read permissions to other groups for this uploaded tar bundle Once the package is uploaded to the server, go to datamotive bin directory, /opt/dmservice/bin We will use the dmcli to upgrade the Datamotive Management server and the node. Enter following command to upgrade. sudo ./dmcli upgrade --username Administrator --path \\<path of the upgrade package> You will be asked for password. Enter the password for given username. The username is Datamotive application username. Command details \u2013 upgrade: Tells dmcli to upgrade the Datamotive build username: Datamotive application user\u2019s name to login to management server. By default, its Administrator path: Path is absolute path where you have uploaded the upgrade bundle (DM_UPGRADE_\\<version>.tar.gz) on current management server E.g. If the Datamotive Upgrade file (DM_UPGRADE_\\<version>.tar.gz) is uploaded to /tmp/ location, then the command would be \u2013 sudo ./dmcli upgrade \u2013path /tmp/DM_UPGRADE_1-0.tar.gz \u2013username Administrator After the successful upgrade of the server and the node, success message would be displayed as per the below snip- Support In case there are any issues or queries while using the solution, feel free to reach out to us @ support@datamotive.io .","title":"User Guide"},{"location":"#_1","text":"","title":""},{"location":"#introduction","text":"Datamotive Hybrid Multi-Cloud Workload Mobility and Business Continuity product suite delivers a disaster recovery and workload migration service and offers cloud economics to help keep your disaster recovery and migration costs under control. Datamotive Workload Mobility can be used to protect your virtual machines/instances on primary site by replicating them periodically to the recovery site. The protected virtual machines/instances can then be recovered as needed in the recovery site as native instances (E.g., protected virtual machine is recovered as a native AWS EC2 instance or a GCP Compute instance). Current release of product has been tested on VMware, AWS and Azure as Protected Site and VMware, AWS, GCP and Azure Cloud as Recovery Site. This document provides information about how to install and configure Datamotive solution. It also provides a general overview of Datamotive solution and it\u2019s different components. Intended Audience This information is intended for anyone who wants to use Datamotive solution. The information is written for experienced Windows or Linux system administrators who are familiar with virtual machine technology and datacenter operations. Supported Datamotive Solution Version The contents of this guide are applicable to Datamotive solution EasyMigrate & EasyHybridDR version 1.x","title":"Introduction"},{"location":"#datamotive-component-architecture","text":"Datamotive solution is composed of following components deployed as independent virtual machines . All the components are shipped either as virtual appliances or cloud native machine images depending on the target infrastructure Datamotive Management Server \u2013 a virtual appliance deployed in protected or recovery site infrastructure where the virtual machines need to be protected or recovered or migrated. Management Server provides user interface (UI), a CLI and RESTfull APIs for the IT administrators to perform Day0-DayN activities. The server also acts as replication node. It is shipped as an OVA for VMware environment & cloud native machine image for AWS, GCP & Azure environments. Management server supports parallel replication & recovery for smaller loads (Upto 20 Virtual Machines disks) Datamotive Replication Node \u2013 a virtual appliance deployed in protected or recovery site . It is used to execute the data replication jobs. This node can be used to increase the overall replication capacity of the solution based on the number of protected VMs/instances. Maximum number of parallel replication jobs (1 replication job per protected disk/volume) supported by each node is defined by the limit provided by Cloud platforms (AWS: 20, GCP: 128) . However, for optimum performance, Datamotive solution limits the capacity of each replication node to 20 parallel disks. It is shipped as an OVA for VMware environment & cloud native machine image for AWS, GCP & Azure environment. Datamotive solution scales horizontally using the Replication Nodes Datamotive Prep Node \u2013 a Windows virtual appliance deployed in the recovery site infrastructure (VMware, AWS, GCP or Azure). This appliance is powered-on and used only when Windows VMs are getting recovered or migrated. It is shipped as an OVA for VMware environment & cloud native machine image for AWS or GCP environment. Each Prep Node supports parallel replication & recovery for smaller loads (Upto 20 Virtual Machines disks). Datamotive solution scales horizontally using the Prep Nodes Datamotive DeDup Node \u2013 a virtual appliance deployed in the recovery site (public cloud) infrastructure (AWS, GCP and Azure). It maintains the checksum & data for data chunks transferred to this site. DeDup node provides an interface to check and provide data chunks whenever queried. It is shipped as native cloud image for AWS, GCP and Azure environments. Following diagram shows the deployment & network topology of these nodes","title":"Datamotive Component Architecture"},{"location":"#what-can-you-do-with-datamotive","text":"Datamotive currently provides fully functional and intuitive GUI, APIs & Python SDK for performing all supported operations. Once deployed, admins can access the Datamotive GUI by logging in to the Management Server on Protected Site. The URL for accessing the management server is Server IP Address>:5000. Default credentials to access the application are administrator/admin . DR Administrators can perform following set of Day1-DayN operations using the Datamotive GUI. Subsequent sections of this document describe the user interface and related options in detail. Category Action/Activity Description Quick Link Provisioning Nodes Management Management of different nodes of Datamotive solution Nodes Configuration Site Management Creation and management of protected & recovery sites using the nodes already created Sites configuration Protection & Recovery Protection Plan Create & manage protection plans for workload protection Protection Plans Test Recovery Validate replicated instances through non-disruptive test recovery Test Recovery Full Recovery Recover protected instances on recovery site Full Recovery Migration Migrate instances from source to target platform Migration Reverse Reverse/Re-protect VMs to original source Reverse Monitoring Replication/Recovery Jobs View replication & recovery jobs for their replication statuses Jobs Events/Alerts View, Acknowledge, Take Action on Events & Alerts Monitor Infrastructure Monitor & Detect changes in protected instances and take appropriate corrective actions on recovery instance configuration Configuration User Management View users of system with their roles & privileges Users Bandwidth Throttling Configure bandwidth usage for changed data transfer Throttling Email Settings Configure email settings to enable email notifications for supported alerts Email Tech Support Manage support bundle creation for troubleshooting purposes Tech Support Scripts User defined custom scripts to be executed during recovery operations Scripts License Manage licenses License","title":"What can you do with Datamotive"},{"location":"#support-matrix","text":"","title":"Support Matrix"},{"location":"#infrastructure","text":"Component Support Source Platforms VMware, AWS & Azure Target Platforms VMware, AWS , Azure & GCP Workloads Virtual Machines with directly attached block storage VMware First Class Disks Component Supported Versions VMware vCenter Server vCenter Server 6.5 (U3) vCenter Server 6.7 vCenter Server 6.7 (U1, U2, U3) vCenter Server 7.0 ESXi Host ESXi 6.5 (GA, U1, U2) ESXi 6.5 (U3) ESXi 6.7 (GA, U1, U2) AWS EC2 GCP Machines Azure Virtual Machines","title":"Infrastructure"},{"location":"#guest-oss","text":"Component Supported Versions CentOS 7.9 Kernel Versions: 3.10.0-1160.80.1.el7.x86_64 3.10.0-1160.76.1.el7.x86_64 3.10.0-1160.71.1.el7.x86_64 3.10.0-1160.66.1.el7.x86_64 3.10.0-1160.62.1.el7.x86_64 3.10.0-1160.59.1.el7.x86_64 3.10.0-1160.53.1.el7.x86_64 3.10.0-1160.el7.x86_64 7.8 Kernel Versions: 3.10.0-1127.19.1.el7.x86_64 3.10.0-1127.18.2.el7.x86_64 3.10.0-1127.13.1.el7.x86_64 3.10.0-1127.el7.x86_64 8 stream 4.18.0-408.el8.x86_64 (ext4 filesystem) 8.2 Kernel Versions: 4.18.0-193.el8.x86_64 4.18.0-193.28.1.el8_2.x86_64 8.5 Kernel Versions: 4.18.0-348.el8.x86_64 4.18.0-348.23.1.el8_5.x86_64 8.6 Kernel Versions: 4.18.0-372.26.1.el8_6.x86_64 RHEL 7.9 Kernel Versions: 3.10.0-1160.80.1.el7.x86_64 3.10.0-1160.76.1.el7.x86_64 3.10.0-1160.71.1.el7.x86_64 3.10.0-1160.66.1.el7.x86_64 3.10.0-1160.62.1.el7.x86_64 3.10.0-1160.59.1.el7.x86_64 3.10.0-1160.53.1.el7.x86_64 3.10.0-1160.el7.x86_64 7.8 Kernel Versions: 3.10.0-1127.19.1.el7.x86_64 3.10.0-1127.18.2.el7.x86_64 3.10.0-1127.13.1.el7.x86_64 3.10.0-1127.el7.x86_64 8.2 Kernel Versions: 4.18.0-193.el8.x86_64 4.18.0-193.28.1.el8_2.x86_64 8.5 Kernel Versions: 4.18.0-348.el8.x86_64 4.18.0-348.23.1.el8_5.x86_64 8.6 Kernel Versions: 4.18.0-372.26.1.el8_6.x86_64 Ubuntu Ubuntu 14: 4.4.0-148-generic Ubuntu 16: 4.15.0-45-generic 4.15.0-142-generic 4.10.0-28-generic Ubuntu 18 5.4.0-42-generic, 5.4.0-72-generic 5.4.0-91-generic Ubuntu 20: 5.11.0-27-generic Oracle Linux Oracle 7.8 4.14.35-1902.300.11.el7uek.x86_64 4.14.35-2047.519.2.1.el7uek.x86_64 Oracle 7.9 5.4.17-2102.201.3.el7uek.x86_64 5.4.17-2136.313.6.el7uek.x86_64 Windows Standard & Datacenter editions of following versions. 2K12 R2 2K16 2K19 SUSE Suse 15 SP3 Kernel version: 5.3.18.57-default Suse 15 SP2 Kernel version: 5.3.18.22-default","title":"Guest OSs"},{"location":"#client-browsers","text":"Component Supported Versions Google Chrome 99.0.4844.82 99.0.4844.84 107.0.1418.56 107.0.5304.122 Microsoft Edge 100.0.1185.29 107.0.1418.56 Mozilla Firefox 98.0.2","title":"Client Browsers"},{"location":"#features","text":"","title":"Features"},{"location":"#authentication","text":"Open the Datamotive UI through URL: \\< Datamotive_Service_IP >:5000 Provide the username and password and press Login On successful login, User will see the Datamotive Dashboard. By default Datamotive will create following three users Administrator DRadmin Guest Default password for all the users is \u2018admin\u2019 Note: If you are login first time then for security reasons password change is must. Provide the current password and new password. Click on change password button to set new password for the system.","title":"Authentication"},{"location":"#dashboard","text":"The Dashboard provides you with an at-a-glance overview of the data protection status of your environment. The Dashboard contains the following features. Title Windows Title windows will give overall status on your configured and protected environment. Title Description Sites Sites configured on the node. Protection Plans Protection plans configured. Protected Machines Total number of protected virtual machines Storage Overall protected storage size. Alert Statistics Active/Unacknowledged alerts which need a user action acknowledgement or action. RPO and RTO Statistics Current recovery time objective and recovery point objective. Title Description RPO Average recovery point objective value RTO Average of recovery time object value Test Executions Test executions completed successfully. Full Recovery Virtual machines recovered successfully. Migrations Virtual machines migrated successfully. Replication Statistics Replication statistics provides an overview of your protected environment replication jobs. Label Description Completed Successfully completed replication iterations. Running Replication iterations which are in-progress. Failed Failed replication iterations. Change Rate Average data change rate for all protected virtual machines Data Reduction Average percentage of data reduction for all the completed replications. Jobs Jobs shows the recently started or completed task in the system. Virtual Machine Protection Analysis Virtual machine protection analysis shows the overall status of recovery site environment in terms of total discovered virtual machines with percentage of protected and unprotected virtual machines. In addition to protection analysis, this wizard also provides the details for replication statistics of virtual machines which are in-sync and not in-sync. Bandwidth Usage Bandwidth usage provide the details network usage of the system for last 12 hours. The bandwidth usage chart shows data downloaded and uploaded for last 12 hours. Site Connections Provides connection details of configured sites in terms of data flow i.e., from which source site data replication is configured for target site. Events Events are records of user actions or system actions that occurred in the Datamotive system. The Events widget provides most recent 5 events generated in the system. Nodes This section displays all the nodes registered with the management node along with their status. This is a snapshot for how different nodes in Datamotive are working together.","title":"Dashboard"},{"location":"#nodes-configuration","text":"Nodes are entities where the Datamotive server is installed (Ex. AWS, GCP, VMWare, Azure, etc.). Datamotive Nodes are of different types like Management, Replication, Dedup & Win Prep. Each node has specific functionality. Management: Node for performing Datamotive management operations. There must be one and only Management node for each site (vCenter Server for VMware & a Region/Zone in Cloud). Management also has a replication engine which allows it to double up as replication node too. Replication: Nodes responsible for performing replication activities. These can be added based on number of Virtual Machine disks to be replicated in parallel. Any number of nodes can be added to meet the requirement for large scale environment. Dedup: This is a special type of node required to support deduplication. This node is required only on the Recovery site. Win Prep: This is also a special type of node required only on Recovery site to perform Windows workloads recovery. For all the nodes, Datamotive provides separate OVAs & cloud specific machine images. Once Node of given type is deployed in the infrastructure, it needs to be added in the Datamotive Management server. Nodes must be deployed and configured in following manner. Management Node: Deploy 1 management node per protected site. Local node representing the management node automatically gets registered. Remote Management Node: Deploy 1 management node per recovery site. Register the management nodes from Recovery Sites in Management Node of Protected Site. Replication Nodes: Deploy replication node based on load. Once deployed register replication node in the local management server. Replication nodes are always added to local management node only. Currently, Datamotive supports replication of 20 virtual disks per replication node. Dedup Node: Deploy the Dedup node on Recovery Site. Once deployed, register the Dedup node with Management Node on the Recovery Site. Win Prep Node: Deploy the Win Prep node on Recovery Site. Once deployed, register the Win Prep node with Management Node on the Recovery Site. To Access Node option, Go to Configure -> Nodes (Note- By default the Local node will be configured.) To add new node - Click On \u201c+ New \u201d option as shown below - It consists of the below options- Name Name to identify the node. For management node, the name must be \u201cdm-repl-server\u201d. For all other nodes, the name has to be same as that of name of the VM where this node is deployed. Hostname This is FQDN or IP address of the server Username This is the username of the Datamotive Engine Password This is the password of the Datamotive Engine Type The type of Datamotive server which is being added. Type consists of 4 options - Management, Replication, Prep Node and Dedupe Server In Type select the appropriate option from the drop down - Type Description Management Core management server Replication Used for replicating the changed data from source to target & during recovery operations Prep Node Prep Node is used when you would want to recover the Windows server Dedupe Server Used for de-duplication of data (Note \u2013 Based on the selection of Type, further details need to be entered). Ex. In option, the management type is selected. It consists of the below options - Platform Type Platform where the node is deployed Management port Port on which the management service runs (By default, it 5000) Replication Data Port Port on which the replication data service runs (By default, it 5001) Replication Controller Port Port on which the replication controller service runs (By default, it 5003) Encryption Key Data will be encrypted using this key while transferring from one node to another node. The key for the node can be accessed in the remote management node, under the node configuration section. Once the details are entered click on Configure option.","title":"Nodes Configuration"},{"location":"#sites-configuration","text":"Sites are infrastructure where the source or target workloads reside. Site consists of platform type and platform details. In the Datamotive UI, go to Configure tab on the left-hand side panel and select Sites. Site can be of following types: Protection - A protection site is the source of the protection plan workload replication. Recover - A Recover site is the destination for the protection plan workload replication. Create Site To create site, click the \u201c+ New\u201d button and Create site windows will pop-up. The common inputs are Name Desired name to identify the site Description Short information about the site Site Type (Protect/Recover) - Select the site type based on source or destination. Platform Type Select the Platform type - VMware/AWS/GCP/Azure Node Select the node based on the Platform type where the workloads are hosted (Note: Based on the platform type and node the options change) Platform Specific Parameters: Platform Type Parameter Description VMware vCenter Server IP Enter the vCenter Server IP address where the workloads are hosted Port Enter the Port on which vCenter Server is running. Default is 443 Username Enter the vCenter Server username Password Enter the vCenter Serer password AWS Region Select the desired region where the workloads will be Protected/Replicated/Recovered Zone Select the desired zone in the region where the workloads will be replicated/recovered Access Key AWS User Access Key Secret Key AWS User Secret Key GCP Region Select the desired region where the workloads will be replicated/recovered Zone Select the desired zone in the region where the workloads will be replicated/recovered Project ID Enter the project id from the GCP console Azure Region Select the desired region where the workloads will be replicated/recovered Subscription ID Enter the Azure subscription ID Storage Account Enter the Azure storage account used for target VM storage Tenant ID Enter the Azure AD App Tenant ID Client ID Enter the Azure AD App Client ID Secret Key Enter the Azure AD App client secret key Click on configure to create the site and on successful creation, site will be listed in the list view. V Center Server IP Edit Site To Edit a site, click on Edit button and then Edit windows will pop-up. Edit the input which need to be changed and click on configure to save the configuration. Remove Site Click on Remove button to delete one or more sites. On click of confirm, the sites will be deleted. Make sure that site isn\u2019t referred in any Protection Plan before removing.","title":"Sites configuration"},{"location":"#protection-plans","text":"Protection Plans are the core units for protecting the workloads. Protection Plans define source & target sites, virtual machines to be protected, their boot orders, replication schedule, recovery configuration for the virtual machines. All of these steps are configured using a wizard. Based on this information, Datamotive performs the replication & recovery operations.","title":"Protection Plans"},{"location":"#create-protection-plan","text":"To create a new protection plan, click on + New button in protection plan list, create protection plan wizard is shown. Follow the guided steps to configure protection plan. Prerequisite VMware platform: VMware tools must be installed in all the Virtual Machines which needs to be protected. CBT (Change block tracking) must be enabled for all the Virtual Machines and their disks. Step 1: General Name Desired name of the protection plan Protect Site Source protection site Recovery Site Destination recovery site Step 2: Virtual Machines Select the virtual machines to be protected and click next. Use search & pagination to find virtual machines. Step 3: Recovery Configuration Provide the virtual machine specific recovery configuration which will be used for creation of instance on recovery site. Recovery configurations vary based on Recovery Site Type. Below are the options user need to configure for each protected instance. General For target cloud platforms, following information is required to be provide by user. All the values are fetched live from the target platform and only the ones available and supported are provided as an option. Instance Type Instance type on cloud site - Example t2.micro on AWS or n1-standard-1 on GCP Volume Type Instance volume type on cloud site - Example GP-2 on AWS or standard on GCP. Volume IOPs IOPs value for supported Volume Types. Please note that the IOPs values are submitted for volume creation without validations. Make sure that all the rules specific to selected volume type are followed while specifying the IOPs value Tags Instance tags. Example \u2013 Tag Key \u2013 Name Tag value \u2013 dm-repl-node For VMware as target platform, the user has to provide selection for following fields Location Folder in target vCenter server where the VM needs to be placed Compute ESXi Host (standalone) or ESXi Host Cluster where the VM needs to be deployed Storage Datastore (standalone) or Datastore Cluster where the VM\u2019s all the disks will be placed CPU Number of vCPUs to configure for the VM Memory Amount of memory to be configured for the VM For Azure as target platform, the user has to provide selection for following fields Resource Group Resource group in target Azure subscription Availability Zone Availability zone in which the VM will be deployed VM Size Virtual Machine size on Azure cloud \u2013 Example Standard_B2s Volume Type Virtual Machine volume type on Azure cloud \u2013 Example Premium SSD Tags Virtual Machine tags. Example \u2013 Tag Key \u2013 Name Tag value Network For instance, network configuration click on config button, will open a network configuration popup window. Network configurations vary based on the target platform For AWS platform as recovery site, the following configuration options are provided- VPC Virtual Private Cloud (Amazon VPC) enables you to launch AWS resources into a virtual network that you've defined. Create from Source This option is used when you need to copy the network configuration from the source instance. All the options like subnets, IP address and security groups get auto-filled as the source instance. This option is supported only in case of AWS to AWS Subnet Subnet ID which will assigned to the instances in this protection plan. For AWS to AWS, subnets from all zones within target region are displayed. From any other source to AWS, subnets from zone where the Datamotive node is deployed are displayed. Datamotive supports multi-zone recovery only when both source and target is AWS. Auto Public IP Click on the checkbox if you want to auto assign a public Ip to instance. Note - only one network card can be configured if public Ip is enabled. Elastic IP Select from allocated elastic IP address pool if any. Private IP Provide the internal IP address for the instance or leave blank for auto assignment. (Please ensure to specify Private IP in the same range as that of given Subnet and is unique too) Security Groups Select the security groups all configure inbound and outbound traffic for the instance. For GCP platform provided the following details Network Network which will be assigned to the recovered instances in the Protection Plan Subnet Subnet ID which will assigned to the instances in this protection plan Private IP Provide the internal IP address for the instance or leave blank for auto assignment. External IP Select one of the following options if external Ip address is required for the selected network card else select none. 1. Auto: GCP will assign a Ip address from its public Ip pool. 2. None: select if external not required. 3. Reserved IP address, GCP project reserved Ip address, will be listed along with above two options. You can select any reserved Ip address from the list. Network Tier Network Service Tiers lets you optimize connectivity between systems on the internet and your Google Cloud instances. Premium Tier delivers traffic on Google's premium backbone, while Standard Tier uses regular ISP network. Firewall Tags The target tag defines the Google Cloud VMs to which the rule applies For VMware platform provided the following details Network Network which will be assigned to the recovered instances in the Protection Plan Adapter Type Adapter type to be configured to the Virtual Machine. This is a complete list of vSphere supported adapter types. User has to carefully select the appropriate adapter which is available in his setup Mac Address Assign a specific Mac Address to a NIC of the VM. When left empty, default Mac Address is assigned by vCenter Server Configure Guest Network Select this option if you want configure static IP address to a NIC of the VM. When selected static IP configuration fields show up IP Address IPV4 address to be assigned to the VM Subnet Mask Subnet mask as applicable from the network Default Gateway Default gateway to be used for communication DNS Server One or more DNS servers specified in a comma separated list For Azure platform as recovery site, the following configuration options are provided- Virtual Network Virtual Network enables you to launch Azure VM into a virtual network that you've defined. Subnet Subnet ID which will assigned to the VM in this protection plan. Private IP Provide the internal IP address for the VM or leave blank for auto assignment. (Please ensure to specify Private IP in the same range as that of given Subnet and is unique too) Public IP Select any public IP from the pool or select auto for automatic assignment Security Groups Select the security groups all configure inbound and outbound traffic for the VM. Step 4: Replication Scripts Datamotive supports executing custom scripts at various levels to allow all the customizations users need for replication & recovery workflows. The scripts are supported for individual VM and complete protection plan as well. The scripts are available as both, pre and post hooks. To use pre or post scripts, first upload the pre & post scripts to Datamotive management node on both protected & recovery sites using scripts section in settings. Once the scripts are uploaded, they will be visible in the pre and post replication scripts option. Datamotive currently supports Python 3.x, Golang & Shell executable scripts. All the scripts must be in form of executables to work. E.g. they should get executed as ./\\<script_file_name>. Scripts are supported at following different levels. The scripts are also executed in the below order during replication & recovery operations. Script Type Execution Level Script Description Replication Protection Plan Pre-Script Executed in each replication iteration as a first step. Virtual Machine Pre-Script Executed in each replication iteration before every virtual machine\u2019s snapshot is taken Virtual Machine Post-Script Executed in each replication iteration after virtual machine\u2019s snapshot is completed Protection Plan Post-Script Executed in each replication iteration after all the virtual machine\u2019s snapshot operation is completed Recovery Protection Plan Pre-Script Executed during Test/Full Recovery & Migration operations as a first step Virtual Machine Pre-Script Executed before starting recovery of every virtual machine Virtual Machine Post-Script Executed after every virtual machine is recovered Protection Plan Post-Script Executed after completion of recovery operation for all virtual machines. Following screens show options where user can select/upload various scripts. Scripts Input Currently, Datamotive supports only binary for execution. The runtime available for scripts is Shell, Bash, Python 2.x & GOLang. In future, binding for different languages will be provided. On invocation the recovery scripts, Datamotive provides following parameters in the order. Pre-script: \\<None> Post-script: JSON string with following format { [ { \u201cName\u201d: \\<VM Name>, \u201cSourceID\u201d: \\<Platform ID of source VM>, \u201cTargetID\u201d:\\<Platform ID of recovered VM>, \u201cNetworkInfo\u201d: [{ \u201cPublicIP\u201d: \\<Public IP if assigned to recovered VM>, \u201cPrivateIP\u201d: \\<Private IP if assigned to recovered VM> }], \u201cCredentials\u201d: { \u201cUsername\u201d: \\<Login username of the recovered VM>, \u201cPassword\u201d: \\<Login password of the recovered VM> } } ] } Scripts Output The scripts are checked for it\u2019s completion and the process exit status is captured. If there are no errors in executing the script, Datamotive considers it to be successfully executed. If there are errors, the recovery is marked as Partially Completed. Step 5: Boot Order Using boot order configuration defines the boot delay and virtual machine boot order. Boot Delay : Delay in seconds between virtual machines specified in the boot order Boot Order : Order in which virtual machines will get recovered or migrated. Lower number will get recovered first Step 6: Replication Configuration Replication configuration allows user to specify the schedule for periodic replication of protected virtual machines. User can configure following parameters. Start Time Time from when protection plan replication will start. Replication Interval Time interval in which the virtual machine\u2019s changed data will be replicated Encryption on Wire Data encryption while transferring from source to destination. Compression Data compression while transferring from source to destination Dedup Enables the data deduplication. Note: Deduplication node should be pre-configured on recovery site before using this feature Differential Reverse Replication Enable this feature if you want to allow recovered machines from the recovery site to replicate back to its original source site. Step 7: Scripts As described in earlier scripts section, these are Replication & Recovery scripts at Protection Plan level. The runtime available for scripts is Shell, Bash, Python 2.x & GOLang. In future, binding for different languages will be provided. On invocation the recovery scripts, Datamotive provides following parameters in the order. Pre-script: \\<None> Post-script: Post script gets 3 ordered parameters Recovered VM information: JSON string with following format {\"vms\":[ { \"name\":\\<VM Name>, \"sourceID\":\\<Platform ID of source VM>, \"targetID\":\\<Platform ID of target VM>, \"ips\":[ {\"publicIP\":\\<Public IP if assigned>, \"privateIP\":\\<Private IP is assigned>} ], \"credentials\":{ \"username\":\"\\<Recovered VM logon username>\", \"password\":\\<Recovered VM logon password> } } ] } User Inputs: As provided by user. Output of Recovery Pre-Script: JSON string with following format {\"status\":\"\",\"code\":0,\"message\":\"\",\"data\":\"\"} Step 8: Summary Review the summary for the protection plan and click finish to configure the protection plan. On successful configuration, replication jobs will start for the virtual machines selected for this protection plan.","title":"Create Protection Plan"},{"location":"#protection-plan-actions","text":"Action on protection plan is available through the protection plan list and through the protection plan details page. Action will get enable depending upon the context and state of the protection plan. Protection Plan actions also differ based on whether the plan is viewed on protected site or recovery site. Certain actions are available only at one site as shown below Actions available through the protection plan details Actions for source site Actions for recovery site Actions available through the protection plan data grid view on source site New: Click to configure new protection plan. Edit: Select protection plan from the list and click edit. Edit protection plan wizard will get open. In edit protection following operations were allowed Add new virtual machine to plan. Remove protected virtual machine from the plan. This action gets completed on next successful iteration of the protection plan. The VM shows as \u201cRemoving\u201d till that time. Recovery configuration modification. Boot order configuration & modification. Replication configuration Scripts modification. Start : Start Replication for the selected protection plan. Stop: Stop the protection plan replication. Remove: To remove the protection plan, click on the Remove button and it will ask for the confirmation. On confirm, the protection plan will get deleted. Note protection plan should be in stopped state with no running jobs.","title":"Protection Plan Actions"},{"location":"#recovery","text":"After the Protection Plans are configured and replication of virtual machines is in-sync, user can trigger various recovery operations from the Datamotive Management Server on the recovery site. To initiate recovery or migration go to Configuration \u2014> Protection Plan -> Click on the protection plan on which recovery or migration operation need to perform. Click on the Actions button. All available operation will get listed.","title":"Recovery"},{"location":"#test-recovery","text":"Prerequisite At least one replication job has been completed successfully for the virtual machine and the sync status for that job should be In-sync. Step 1: Select Virtual Machines Select the virtual machines for the test recovery. Provide the credentials to execute the pre and post scripts. If there are no scripts for the virtual machine, then credentials are not mandatory. Credentials are not stored anywhere and only been used for the workflow. NOTE: For Windows recovery on AWS, Credentials are mandatory even if there are no scripts. Step 2: Test Recovery Configuration Configure test recovery instance for it\u2019s compute, storage & network to ensure a non-intrusive test recovery drill. Step 3: Tools & Scripts Install System Agents: For AWS, install OS agents like EC2Launch and SSMAgents. For GCP, install google os-config and compute-engine agents. For Azure, install Azure VM agent Install Cloud Packages : For AWS. install AWS Cloud SDK and for GCP, install GCP Cloud SDK. For VMware only Install System Agents is available as there no cloud packages Cleanup: Select this flag to clean-up all previously created test recovered instances for selected VMs Run Protection Plan level scripts: Select this option if you want to execute recovery scripts configured at protection plan level. Typically, these scripts perform changes to infrastructure like DNS entry changes etc. which is not desirable in case of test recoveries. If you have configured such scripts and do not wish to execute them in Test Recovery cycles, you can skip this step. Step 3: Summary Review the summary and click on finish to start the test recovery. This will start the test recovery jobs for the selected virtual machines and jobs can be monitored in the Jobs \u2014> Recovery. Test Recovery validation Check the status of the virtual machine's recovery jobs in the Jobs \u2014> Recovery. Check the Cloud Console (AWS, Azure and GCP) for the instances with the virtual machines name and their running status. AWS also has status checks. On successful completion of recovery jobs, IP Address can be found for the new running instances. For Windows machines, download the RDP file by click the download button right next to the IP address and check the windows machine through RDP. For Linux machines, copy the IP address and check the linux machine through ssh. Note: Once the validations are completed, Datamotive recommends to remove the Test Recovered instance. Leaving test recovered instances running may lead to increased cloud cost.","title":"Test Recovery"},{"location":"#full-recovery","text":"To perform full recovery after disaster in the source site, open Management Application on Recovery Site and go to Configuration \u2014> Protection Plan \u2013> Click on the Protection plan. Click on Action button and select Recovery Prerequisite: At least one replication job has been completed successfully for the virtual machine and the sync status for that job should be init-success. Step 1: Select Virtual Machines Select the virtual machines for the recovery. Provide the credentials to execute the pre and postscripts. If there are no scripts for the virtual machine, then credentials are not mandatory. Credentials are not stored anywhere and only been used for the workflow. NOTE: For Windows recovery on AWS, Credentials are mandatory even if there are no scripts. Step 2: Recovery Configuration Install System Agents: For AWS, install OS agents like EC2Launch and SSMAgents. For GCP, install google os-config and compute-engine agents. For Azure, install Azure VM agent. Install Cloud Packages : For AWS. install AWS Cloud SDK and for GCP, install GCP Cloud SDK. Step 3: Recovery Summary Review the summary and click on finish to start the recovery. This will start the recovery jobs for the selected virtual machines and jobs can be monitored in the Jobs \u2014> Recovery. NOTE: If the replication job is on-going at the time of Full Recovery, then the instance will be recovered from the last known good state. Recovery Job Status","title":"Full Recovery"},{"location":"#migration","text":"Migration also follows the recovery workflow for the protected VMs. To migrate the workloads, go to Configuration \u2014> Protection Plan \u00e0 Click on the protection on which migration need to perform, on the Recovery site. Click on actions buttons and select Migrate Prerequisite: In case of migration, to make sure there is no loss of data, the virtual machine(s) should be in power off state and the last replication jobs should be successfully completed with zero changed data. Step1: Select Virtual Machines Select the virtual machines and provide the credentials if there are pre- or post-configured for these virtual machines. Note: For Windows machine in AWS, credentials are mandatory. Step 2: Recovery Configuration Install System Agents: For AWS, install OS agents like EC2Launch and SSMAgents. For GCP, install google os-config and compute-engine agents. For Azure, install Azure VM agent. Install Cloud Packages : For AWS. install AWS Cloud SDK and for GCP, install GCP Cloud SDK. Step 3: Summary Review the summary and click on finish to start the Migration . This will start the test migration jobs for the selected virtual machines and jobs can be monitored in the Jobs \u2014> Recovery jobs. Job's view after migration completed","title":"Migration"},{"location":"#reverse","text":"The Reverse protection plan or Re-protect option is available when the Virtual Machines needs to be replicated back to the original Source Site (Especially in case for Disaster Recovery) Currently reverse is supported from AWS/VMware/Azure to AWS/VMware/Azure. Reverse option is available at protection plan level under the Actions option. The option is enabled only after the protection plan is fully recovered. After the reverse option is clicked, the pop-up for the reverse workflow opens - Replication Type: The option allows you to configure the Replication Type. Following replication options are available to be configured. Full Incremental \u2013 With this option entire workload data is replicated back to the original source site in the 1st iteration and then onwards the incremental data (changed data) is replicated. This option has to be used when In the original plan, \u201cEnable Reverse Differential\u201d option was not selected Even after \u201cEnable Reverse Differential\u201d option was selected, the original site does not have same state from which the workloads were recovered. Same state is defined when the state of infrastructure (Hosts, Datastores, VMs, their snapshots) etc. is exactly the same as what it was before the disaster. Differential- With this option only the differential data which is changed on current source is transferred back to original source. This option ensures that complete workload is not transferred back and hence the replication process is fast. This option can be used only when the \u201cEnable Reverse Differential\u201d option was selected in the original plan before the Full Recovery Recovery Machines Suffix: Configure desired suffix which will be assigned to the recovery entities created on the original source site. This helps differentiate the replicated workloads from the original ones while reverse protecting them. Replication Interval: Configure desired replication interval for reverse protection As a next step, the Recovery Configuration wizard would appear \u2013 The step allows to configure recovery entity properties supported by the target platform. For example, the screenshot shows details for VMware platform where user can select Location \u2013 Desired location/folder where the recovered VM would reside Compute \u2013 The Host IP address Storage \u2013 The datastore in the host CPU \u2013 Number of CPU assigned to the recovered VM Memory - Memory assigned to the recovered VM In Network, the networks assigned to that particular VM will be visible and the when the config option is clicked the network and Subnet/Network Adapter The next step allows to reconfigure the scripts, so that all the automation can be done in target platform. The scripts function in the same way as that of forward recovery. Below table illustrates different types of scripts supported by Datamotive platform. Script Type Execution Level Script Description Replication Protection Plan Pre-Script Executed in each replication iteration as a first step. Virtual Machine Pre-Script Executed in each replication iteration before every virtual machine\u2019s snapshot is taken Virtual Machine Post-Script Executed in each replication iteration after virtual machine\u2019s snapshot is completed Protection Plan Post-Script Executed in each replication iteration after all the virtual machine\u2019s snapshot operation is completed Recovery Protection Plan Pre-Script Executed during Test/Full Recovery & Migration operations as a first step Virtual Machine Pre-Script Executed before starting recovery of every virtual machine Virtual Machine Post-Script Executed after every virtual machine is recovered Protection Plan Post-Script Executed after completion of recovery operation for all virtual machines. Once the Next option is clicked, the below wizard for configuring the boot order appears \u2013 Using boot order configuration defines the boot delay and virtual machine boot order. Boot Delay : Delay in seconds between virtual machines specified in the boot order Boot Order : Order in which virtual machines will get recovered or migrated. Lower number will get recovered first On clicking Next button, options to set replication configuration is available- Replication configuration allows user to specify the schedule for periodic replication of protected virtual machines. User can configure following parameters. Start Time Time from when protection plan replication will start. Replication Interval Time interval in which the virtual machine\u2019s changed data will be replicated Encryption on Wire Data encryption while transferring from source to destination. Compression Data compression while transferring from source to destination Dedup Enables the data deduplication. Note: Deduplication node should be pre-configured on recovery site before using this feature Differential Reverse Replication Enable this feature if you want to allow recovered machines from the recovery site to replicate back to its original source site. Clicking the Next button presents the options to set protection plan level scripts. As described earlier in the protection plan creation section, these are Replication & Recovery scripts at Protection Plan level. Next is the Summary which is the last step in the wizard to review the reverse configuration and click finish to reverse the protection plan. On successful reversal, replication jobs will start for the virtual machines in the protection plan and can be viewed in the jobs sections","title":"Reverse"},{"location":"#jobs","text":"Jobs are logs of every replication & recovery action performed in the system. Datamotive maintains detailed information of each job executed by the system. Jobs provide a real time mechanism to view the currently executing operations in the system. Navigation: Jobs You can use the Jobs page to monitor the overall status of replication and recovery jobs.","title":"Jobs"},{"location":"#replication","text":"The Replication Jobs tab provides details about all the running, completed, and failed replication iterations. The Replication job section has the following sub-section to show replication jobs base on the grouping criteria.","title":"Replication"},{"location":"#protection-plan","text":"Navigation: Jobs --> Select Protection Plan. Protection plan replication details provide a list of protection plans. Each protection plan has its associated virtual machine replication information. click icon or title to view protection plan level details. Column Name Description Name Name of virtual machine associated with the protection plan. Iteration The total number of replication iterations completed. Total Changed Total data changed. Total Transferred Total data transferred to the replication server. Data Reduction (%) Overall data reduction. Job Status Status of latest replication iteration. Completed : Replication was completed successfully. Started : Replication is running. Partially Completed : Replication completed with errors. Failed : Replication failed. Sync Status Virtual machine sync status. Init-success : The first iteration completed successfully. Init-in-progress : The first iteration is running. Init-failed : The first iteration failed. In-sync : Iteration is completed within configured replication interval time. Exceeded interval : Iteration is completed but took more time than configured replication interval time. Sync-failed : Replication iteration failed.","title":"Protection Plan"},{"location":"#virtual-machines","text":"Provides a list of replication details for each protected virtual machine. Note: For failed jobs, hover on the Sync Status column to get details of the status. Hover on the Replication Duration column to get Replication start & end time. Column Name Description Virtual Machine Name of the protected virtual machine. Iteration Total number of replication iterations completed. Changed Total changed data discovered. Transferred Total data transferred to the replication server. Replication Duration Time took to complete iteration. Job Status Status of replication iteration. Sync Status Virtual machine sync status.","title":"Virtual Machines"},{"location":"#disks","text":"Provide a list of replication details for each protected virtual machine disk/volume. Column Name Description Virtual Machine Name of the protected virtual machine. Disk Id Disk id of virtual machine. Data Changed Total changed data discovered for the disk. Data Transferred Total data transferred to the replication server. Replication Duration Time took to complete iteration. Job Status Status of replication iteration.","title":"Disks"},{"location":"#recovery-jobs","text":"The Recovery jobs tab provides details about all the running, completed and failed recovery operations.","title":"Recovery Jobs"},{"location":"#protection-plan_1","text":"Protection plan recovery details provide a list of protection plans. Each protection plan has its associated recovered (Full / Test) or migrated virtual machine information. click icon or title to view protection plan level details. Column Name Description Name Name of virtual machine associated with the protection plan. Duration The time required to complete the recovery. Recovery Type Recovery Type (Full Recovery, Test Recovery or Migration) Status Recovery/Migration status.","title":"Protection Plan"},{"location":"#virtual-machines_1","text":"Provides a list of recovered (Test/Full) or migrated virtual machines. Column Name Description Virtual Machine Name of virtual machine. Duration The time required to complete the recovery/migration. Recovery Type Recovery Type (Full Recovery, Test Recovery or Migration) Job Status Recovery job status. Completed : Recovery completed successfully. Started : Recovery job is running. Partially Completed : Recovery completed with errors. Failed : Recovery failed. IP Address Recovered virtual machine IP address.","title":"Virtual Machines"},{"location":"#monitor","text":"Monitor Option is used to see the events, alerts and customized reports as they are generated. Events & Alerts contain audit log information about all the critical actions performed in the system. In Monitor, there are 3 options- Events Alerts Reports","title":"Monitor"},{"location":"#events","text":"Navigation \u2013 Monitor -> Events Events are Datamotive server or user generated incidents which are generated automatically when they occur. There are 4 types of Events Information This are events occurred just for the information Warning This are events occurred to take precautionary action Error This are events occurred when there is an issue and needs to be addressed Critical This are events occurred when there is an issue and that needs to be addressed at the earliest To see \u201cEvents\u201d, go to \u201cMonitor\u201d option and click on \u201cEvents\u201d In events, the following information is displayed \u2013 Date The date and time when the event has occurred Topic The topic of the event Level The level of the event occurred (Ex. Information, warning, Error, Critical) Event type the type of the event occurred Description A short description about the event occurred User User who initiated the event","title":"Events"},{"location":"#alerts","text":"Navigation \u2013 Monitor -> Alerts Alerts are Datamotive server generated warning messages based on the events and are tagged with the severity level they occur. The severity of the alerts is of 4 types - Information These are events for the information Warning These are events which require taking precautionary measures Error These are events which require user attention to address the issue Critical These are events which require immediate user attention to address the issue In Alerts, the following information is displayed \u2013 Title The headline/short description for the alert generated Severity The condition at which the alerts are generated Created The date and time at which the alerts are generated Last updated The date and time at which the alert was checked by the Datamotive server Status The symbol representing the severity of the alert When we click on the Title or Status of a particular alert a window will pop-up with a description regarding that particular alert. It consists of the 2 tabs Info Information about the alert generated Associated Event Event associated with the generated alert The info tab consists of the following \u2013 Severity The condition at which the alerts are generated Event Type The type of event that is associated with the alert Description A short description about the event occurred Created The date and time at which the alerts are generated Updated The date and time at which the alert was checked by the Datamotive server Occurrence The frequency at which the alerts is occurred Acknowledge Message User inputs when the alert is addressed The associated event consists of the following \u2013 Event ID The ID of the event associated with the alerts Level The level of the event occurred (Ex. Information, warning, Error, Critical) Topic The topic of the event Date The date and time when the event has occurred Event Type The type of the event occurred Description A short description about the event occurred Acknowledge Message User inputs when that event is addressed User can perform specific action (system generated) or just acknowledge the alert without taking any action. Certain Alerts, mandate user action to resolve the issue. Once the alert is acknowledged or action is taken by the system, the status of the Alert changes.","title":"Alerts"},{"location":"#reports","text":"Navigation \u2013 Monitor -> Report Datamotive provides mechanism to generate Reports listing Nodes, Events, Alerts or Jobs in the system. To generate reports, go to \u201cMonitor\u201d Tab and click on \u201cReports\u201d option- To generate a Report, click on \u201cFilter\u201d option. Click on the components which you want to include in the report. For Protection plan dropdown select if you want to include all protection plan details in the report. Or select a specific plan whose report is required. Once the options are selected, click on \u201cGenerate Report\u201d for the report to be generated. Click on export button to export data to .pdf or .xlsx format.","title":"Reports"},{"location":"#settings","text":"To configure your environment, you can use settings section. Settings section will allow you to configure email, Bandwidth throttling, license and tech support.","title":"Settings"},{"location":"#license","text":"Location: Settings \u2014> License License is required to perform the recovery and migrations operations. By default, system will provide a trial license which has a fixed number of migrations and recoveries allowed. Once you perform any migration or recovery operation the respective consumption will reflect in its associated consumption bar. License installation For new license installation, contact the support@datamotive.io with following information. Node Key: You can get node key through the about section of the application. Along with node key provide the details requested by the support team. On successful credential validation Datamotive team will provide you a license file. Once you receive the license form the Datamotive team, navigate to the settings -> license Click on +New button to install the received license. A new modal window will popup. Click on the upload icon to select the license file. Post successful validation the detail of the license is shown. If all the license details look good, then click install. New license will get install in the system. If multiple license available in the system, click on the action button to active or deactivate the license.","title":"License"},{"location":"#scripts","text":"Location: Settings \u2014>Scripts Datamotive supports executing custom scripts on recovery of individual virtual machine and complete protection plan as well. Datamotive supports both, Pre & Post scripts. The scripts are executed on the Datamotive management node. To use scripts in protection plan, they need to be uploaded into Datamotive management server on both protected & recovery site. To configure new script, follow below steps. Click on the +New button, new popup will be shown to configure script. Select the script file for the upload Select Pre or Post script type Following actions are available for a uploaded script. Edit: Click on edit icon to edit script. Remove: Click on remove icon to remove script.","title":"Scripts"},{"location":"#email","text":"Location: Settings \u2014> Email Email setting allow you to configure the email and recipients details so that Datamotive can send you the critical alerts details over the email. Configuration. Click on the Configure now to open email configuration window. Provide the required details and click Configure. Email Address Email address used to send the communication alerts. Email Password Email Password for the authentication. Note: System will encrypt these details before saving them in the database. SMTP Host SMTP hostname or SMTP server IP address SMTP Port SMTP port number SSL Certificate Verification Click if your smtp server is secure and SSL certificate is installed on it. Replicate Configuration If multiple sites were already connected to the node from where you are configuring the email and you want same settings should get replicate on all the connected sites, then enable this option. Post email Configuration you can view the configured details along with Email Recipients section get enabled. To add new recipient, click on +New icon Provide email address of the recipient Select the events for which you want to send email to recipients. Click configure to add new recipient in the email list for subscribed events. Using action options, you can reconfigure the recipient's details or can delete them from the list.","title":"Email"},{"location":"#roles","text":"Location: Settings \u2014>Roles Privileges define rights to perform action on an entity of Datamotive. Whereas the role is a set of privileges. Roles are assigned to the user. By default, Datamotive generate following three roles. administrator: With Super Admin role, user can view and perform all the available operations in the system DRadmin: With DR Admin role, user can perform operations related to protection plan and recovery/migration Guest: Read-only user can view all available views but can\u2019t perform any operation. On Left side grid all roles are listed. Click on the role to load its associated privileges and users.","title":"Roles"},{"location":"#users","text":"Location: Settings \u2014>Users Users lists provide all registered users with their assign roles.","title":"Users"},{"location":"#tech-support","text":"Location: Settings \u2014>Tech Support Support bundle is useful to triage the any issue occurred in the system. To collect new support bundle, follow below steps. Click on the +Generate button, new popup will be shown to trigger bundle creation. Provide a proper description specifying why new support bundle generation is requested and click Generate Bundle Post system accepts the generate bundle request it will collect all the required info from the node. Note: This operation may take several minutes complete, you can check the status of bundle in the list. (Click Refresh to update the status) Once support bundle generation completed, in the action section you will get a download icon. Use Download icon to download the support bundle Use delete icon to remove the support bundle from the system","title":"Tech Support"},{"location":"#throttling","text":"Location: Settings \u2014> Throttling Throttling allows you the configure the network usage as per requirement. By default, system will use networks full capacity to download or upload the replication data across the sites. If you want to restrict the bandwidth, use then bandwidth throttling configuration is required. Provide the below details and click configure to apply bandwidth throttling. Enable Limit Enable the option if bandwidth throttling is required. Once enable you can provide the bandwidth usage details by scrolling the usage bar or by entering the values in the usage field. Enable Time Limit If time limit base usage configuration required, then enable the option. Once enable you can provide the bandwidth limits along with its start and end time specification over which time base limits will be applicable. Apply To All Replication Nodes If you want to apply same setting on all the replication nodes, then enable this option. If you want to configure each replication node bandwidth throttling, then click on Icon to configure the node specific usage limits. New popup window will be shown to configure the node specific configuration. Provide the details and click configure. Provided configuration will get applied on the node.","title":"Throttling"},{"location":"#upgrade","text":"The upgrade feature is used to upgrade the Datamotive services, features and the Datamotive UI files. To upgrade Datamotive solution, execute below mentioned steps on the Management server only for server as well as nodes. Upgrade needs to be done individually on management nodes of all sites. Please note that Datamotive management nodes with different versions on different sites may result in inconsistent behaviour and may impact replication and recovery operations. Steps to upgrade the Datamotive Server and the node: Copy the \u201cDM_UPGRADE_ \\<version>.tar.gz\u201d bundle/package to the Management server via Win-scp tool /scp command or any other tool Make sure you give the read permissions to other groups for this uploaded tar bundle Once the package is uploaded to the server, go to datamotive bin directory, /opt/dmservice/bin We will use the dmcli to upgrade the Datamotive Management server and the node. Enter following command to upgrade. sudo ./dmcli upgrade --username Administrator --path \\<path of the upgrade package> You will be asked for password. Enter the password for given username. The username is Datamotive application username. Command details \u2013 upgrade: Tells dmcli to upgrade the Datamotive build username: Datamotive application user\u2019s name to login to management server. By default, its Administrator path: Path is absolute path where you have uploaded the upgrade bundle (DM_UPGRADE_\\<version>.tar.gz) on current management server E.g. If the Datamotive Upgrade file (DM_UPGRADE_\\<version>.tar.gz) is uploaded to /tmp/ location, then the command would be \u2013 sudo ./dmcli upgrade \u2013path /tmp/DM_UPGRADE_1-0.tar.gz \u2013username Administrator After the successful upgrade of the server and the node, success message would be displayed as per the below snip-","title":"Upgrade"},{"location":"#support","text":"In case there are any issues or queries while using the solution, feel free to reach out to us @ support@datamotive.io .","title":"Support"}]}